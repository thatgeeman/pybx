{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate anchor boxes\n",
    "\n",
    "> Methods to generate anchor boxes of different aspect ratios. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp anchor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import inspect\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from fastcore.foundation import L\n",
    "from numpy.typing import ArrayLike \n",
    "from typing import Union\n",
    "\n",
    "from pybx.ops import named_idx\n",
    "from pybx.basics import get_bx\n",
    "from pybx.utils import get_edges, validate_boxes, as_tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate anchor boxes, we need three basic information:\n",
    "\n",
    "- Input image size, `image_sz`: To position our anchor boxes within the maximum \n",
    "coordinates (`width`, `height`) of the image.\n",
    "- Feature map size, `feature_sz`: Feature map is the size (`width`, `height`) \n",
    "of the output of a convolutional operation. A $10\\times10$ feature map would mean \n",
    "$10\\times10$ local receptive field locations can be traced back into the \n",
    "input image. These 100 receptive field locations ($10\\times10=100$) in the input image \n",
    "would act as our initial anchor box candidates.\n",
    "\n",
    "![](https://ars.els-cdn.com/content/image/1-s2.0-S0925231217314169-gr4.jpg)\n",
    "\n",
    "- Aspect ratio of anchor boxes, `asp_ratio`: To generate anchor boxes with \n",
    "different `width` to `height` ratio (default `asp_ratio=1`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def bx(\n",
    "    image_sz: (int, tuple),\n",
    "    feature_sz: (int, tuple),\n",
    "    asp_ratio: float = None,\n",
    "    clip: bool = True,\n",
    "    named: bool = True,\n",
    "    anchor_sfx: str = \"a\",\n",
    "    min_visibility: float = 0.25,\n",
    ") -> ArrayLike:\n",
    "    \"\"\"Calculate anchor box coords given an image size and feature size\n",
    "    for a single aspect ratio.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image_sz : (int,tuple)\n",
    "        image size (width, height)\n",
    "    feature_sz : (int,tuple)\n",
    "        feature map size (width, height)\n",
    "    asp_ratio : float, optional\n",
    "        aspect ratio (width:height), by default None\n",
    "    clip : bool, optional\n",
    "        whether to apply np.clip, by default True\n",
    "    named : bool, optional\n",
    "        whether to return (coords, labels), by default True\n",
    "    anchor_sfx : str, optional\n",
    "        suffix anchor label with anchor_sfx, by default \"a\"\n",
    "    min_visibility : float, optional\n",
    "        minimum visibility dictates the condition for a box to be considered\n",
    "        valid. The value corresponds to the ratio of expected area of an anchor box\n",
    "        to the calculated area after clipping to image dimensions., by default 0.25\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ArrayLike\n",
    "        anchor box coordinates in `pascal_voc` format\n",
    "        if named=True, a list of anchor box labels are also returned.\n",
    "    \"\"\"\n",
    "    labels = None\n",
    "    image_sz = as_tuple(image_sz)\n",
    "    feature_sz = as_tuple(feature_sz)\n",
    "    asp_ratio = 1.0 if asp_ratio is None else asp_ratio\n",
    "    # n_boxes = __mul__(*feature_sz)\n",
    "    top_edges = get_edges(image_sz, feature_sz, op=\"noop\")\n",
    "    bot_edge = get_edges(image_sz, feature_sz, op=\"add\")\n",
    "    coords = np.hstack([top_edges, bot_edge])  # raw coords\n",
    "    coords_wh = coords[:, 2:] - coords[:, :2]  # w -> xmax-xmin, h -> ymax-ymin\n",
    "    coords_center = coords[:, 2:] - coords_wh / 2  # xmax-w/2, ymax-h/2\n",
    "    # scale the dimension of width and height with asp ratios\n",
    "    _w = coords_wh[:, 0] * math.sqrt(asp_ratio)\n",
    "    _h = coords_wh[:, 1] / math.sqrt(asp_ratio)\n",
    "    coords_asp_wh = np.stack([_w, _h], -1)\n",
    "    xy_min = coords_center - coords_asp_wh / 2\n",
    "    xy_max = coords_center + coords_asp_wh / 2\n",
    "    coords = np.hstack([xy_min, xy_max])\n",
    "    # check for valid boxes\n",
    "    b = validate_boxes(\n",
    "        coords, image_sz, feature_sz, clip=clip, min_visibility=min_visibility\n",
    "    )\n",
    "    if named:\n",
    "        anchor_sfx = f\"{anchor_sfx}_{feature_sz[0]}x{feature_sz[1]}_{asp_ratio:.1f}_\"\n",
    "        labels = named_idx(len(b), anchor_sfx)\n",
    "    # init multibx\n",
    "    b = get_bx(b, labels)\n",
    "    return (b.coords, b.label) if named else b.coords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_1, labels_1 = bx(100, 10, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually multiple anchor boxes with different `feature_sz` and `asp_ratio` are \n",
    "needed. This requirement arises in the case of multiscale object detection.\n",
    "\n",
    "For multiscale object detection, feature maps from different convolution \n",
    "operations of the network are used to trace back into the input image, to \n",
    "generate anchor boxes. \n",
    "The `bxs` method of `pybx` provides this possibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def bxs(\n",
    "    image_sz: (int, tuple),\n",
    "    feature_szs: list = None,\n",
    "    asp_ratios: list = None,\n",
    "    named: bool = True,\n",
    "    **kwargs,\n",
    ") -> ArrayLike:\n",
    "    \"\"\"Calculate anchor box coords given an image size and multiple\n",
    "    feature sizes for mutiple aspect ratios.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image_sz : (int,tuple)\n",
    "        image size (width, height)\n",
    "    feature_szs : list, optional\n",
    "        list of feature map sizes, each feature map size being an int or tuple, by default [(8, 8), (2, 2)]\n",
    "    asp_ratios : list, optional\n",
    "        list of aspect ratios for anchor boxes, each aspect ratio being a float calculated by (width:height), by default [1 / 2.0, 1.0, 2.0]\n",
    "    named : bool, optional\n",
    "        whether to return (coords, labels), by default True\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ArrayLike\n",
    "        anchor box coordinates in pascal_voc format\n",
    "        if named=True, a list of anchor box labels are also returned.\n",
    "    \"\"\"\n",
    "    image_sz = as_tuple(image_sz)\n",
    "    feature_szs = [8, 2] if feature_szs is None else feature_szs\n",
    "    feature_szs = [as_tuple(fsz) for fsz in feature_szs]\n",
    "    asp_ratios = [1 / 2.0, 1.0, 2.0] if asp_ratios is None else asp_ratios\n",
    "    # always named=True for bx() call. named=True in fn signature of bxs() is in its scope.\n",
    "    coords_ = [\n",
    "        bx(image_sz, f, ar, named=True, **kwargs)\n",
    "        for f in feature_szs\n",
    "        for ar in asp_ratios\n",
    "    ]\n",
    "    coords_, labels_ = L(zip(*coords_))\n",
    "    coords_ = np.vstack(coords_)\n",
    "    labels_ = L([l_ for lab_ in labels_ for l_ in lab_])\n",
    "    return (coords_, labels_) if named else np.vstack(coords_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords, labels = bxs(100, [10, 8, 5, 2], [1, 0.5, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((579, 4), 579)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords.shape, len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All methods work with asymetric `image_sz` (and or `feature_szs` as well):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords, labels = bxs((100, 200), [10, 8, 5, 2], [1, 0.5, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((654, 4), 654)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords.shape, len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pybx-C1Od1SV-",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
