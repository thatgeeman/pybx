{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thatgeeman/pybx/blob/master/nbs/pybx_walkthrough.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">⚠ Note: walkthrough for v0.1.3 ⚠\n",
        ">\n",
        ">run `! pip freeze | grep pybx` to see the installed version. "
      ],
      "metadata": {
        "id": "hS3q4tgTIIae"
      },
      "id": "hS3q4tgTIIae"
    },
    {
      "cell_type": "markdown",
      "id": "904b9817",
      "metadata": {
        "id": "904b9817",
        "papermill": {
          "duration": 0.022224,
          "end_time": "2022-01-15T18:00:10.052411",
          "exception": false,
          "start_time": "2022-01-15T18:00:10.030187",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# PyBx\n",
        "\n",
        "PyBx is a simple python package to generate anchor boxes (aka default/prior boxes) for object detection\n",
        "tasks. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e8e2cde",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-15T18:00:10.098822Z",
          "iopub.status.busy": "2022-01-15T18:00:10.097516Z",
          "iopub.status.idle": "2022-01-15T18:00:22.057942Z",
          "shell.execute_reply": "2022-01-15T18:00:22.057190Z",
          "shell.execute_reply.started": "2022-01-15T17:50:42.281453Z"
        },
        "id": "8e8e2cde",
        "papermill": {
          "duration": 11.984212,
          "end_time": "2022-01-15T18:00:22.058149",
          "exception": false,
          "start_time": "2022-01-15T18:00:10.073937",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "! pip install pybx  # restart runtime if asked"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a2c01c5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-15T18:00:22.112201Z",
          "iopub.status.busy": "2022-01-15T18:00:22.111307Z",
          "iopub.status.idle": "2022-01-15T18:00:25.550513Z",
          "shell.execute_reply": "2022-01-15T18:00:25.549723Z",
          "shell.execute_reply.started": "2022-01-15T17:50:51.173828Z"
        },
        "papermill": {
          "duration": 3.47227,
          "end_time": "2022-01-15T18:00:25.550709",
          "exception": false,
          "start_time": "2022-01-15T18:00:22.078439",
          "status": "completed"
        },
        "tags": [],
        "id": "2a2c01c5"
      },
      "outputs": [],
      "source": [
        "! pip freeze | grep pybx"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da615c1e",
      "metadata": {
        "id": "da615c1e",
        "papermill": {
          "duration": 0.021105,
          "end_time": "2022-01-15T18:00:25.594171",
          "exception": false,
          "start_time": "2022-01-15T18:00:25.573066",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# SSD for Object Detection\n",
        "\n",
        "This walkthrough is build around the [Single-Shot Detection (SSD)](https://arxiv.org/pdf/1512.02325.pdf) algorithm. The SSD can be imagined as an encoder-decoder model architecture, where the input image is fed into a `backbone` (encoder) to generate inital features, which then goes through a series of 2D convolution layers (decoders) to perform further feature extraction/prediction tasks at each layer. For a single image, each layer in the decoder produces a total of `N x (4 + C)` predictions. Here `C` is the number of classes (plus one for `background` class) in the detection task and 4 comes from the corners of the rectangular bounding box. \n",
        "\n",
        "### Usage of the term Feature/Filter/Channel\n",
        "\n",
        "Channel: RGB dimensione, also called a Filter\n",
        "\n",
        "Feature: (W,H) of a single channel"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d5a9476",
      "metadata": {
        "id": "9d5a9476",
        "papermill": {
          "duration": 0.022256,
          "end_time": "2022-01-15T18:00:25.639322",
          "exception": false,
          "start_time": "2022-01-15T18:00:25.617066",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Example case \n",
        "For this example, we assume that our input image is a single channel image is of shape `[B, 3, 300, 300]` where `B` is the batch size. Assuming that a pretrained `VGG-16` is our model `backbone`, the output feature shape would be: `[B, 512, 37, 37]`. Meaning that, 512 channels of shape `[37, 37]` were extracted from each image in the batch. In the subsequent decoder layers, for simplicity we double the channels while halving the feature shape using `3x3` `stride=2` convolutions (except for first decoder layer where convolution is not applied). This results in the following shapes:\n",
        "\n",
        "```python\n",
        "torch.Size([-1, 512, 37, 37])  # inp from vgg-16 encoder\n",
        "torch.Size([-1, 1024, 18, 18]) # first layer logits\n",
        "torch.Size([-1, 2048, 8, 8])   # second layer logits\n",
        "torch.Size([-1, 4096, 3, 3])   # third layer logits\n",
        "```\n",
        "\n",
        "<img src=\"https://lilianweng.github.io/lil-log/assets/images/SSD-box-scales.png\" width=\"500\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb66a0ee",
      "metadata": {
        "id": "fb66a0ee",
        "papermill": {
          "duration": 0.022428,
          "end_time": "2022-01-15T18:00:25.685695",
          "exception": false,
          "start_time": "2022-01-15T18:00:25.663267",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Sample image\n",
        "Image obtained from USC-SIPI Image Database. \n",
        "The USC-SIPI image database is a collection of digitized images. It is maintained primarily to support research in image processing, image analysis, and machine vision. The first edition of the USC-SIPI image database was distributed in 1977 and many new images have been added since then."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e15563b1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-15T18:00:25.735659Z",
          "iopub.status.busy": "2022-01-15T18:00:25.734695Z",
          "iopub.status.idle": "2022-01-15T18:00:26.940237Z",
          "shell.execute_reply": "2022-01-15T18:00:26.939603Z",
          "shell.execute_reply.started": "2022-01-15T17:50:56.761291Z"
        },
        "id": "e15563b1",
        "papermill": {
          "duration": 1.233139,
          "end_time": "2022-01-15T18:00:26.940386",
          "exception": false,
          "start_time": "2022-01-15T18:00:25.707247",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "! wget -q -O 'image.jpg' 'https://sipi.usc.edu/database/download.php?vol=misc&img=5.1.12'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "baa5c76a",
      "metadata": {
        "id": "baa5c76a",
        "papermill": {
          "duration": 0.021061,
          "end_time": "2022-01-15T18:00:26.983030",
          "exception": false,
          "start_time": "2022-01-15T18:00:26.961969",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## About anchor Boxes\n",
        "\n",
        "We are expected to provide our models with \"good\" anchor (aka default/prior) boxes. Strong opinion: Our model is [only as good as the initial anchor boxes](https://towardsdatascience.com/anchor-boxes-the-key-to-quality-object-detection-ddf9d612d4f9) that we generate. Inorder to improve the coverage of our model, we tend to add additional anchor boxes of different aspect ratios. Now, for a single image, each layer in the decoder produces a total of `N x A x (4 + C)` predictions. Here `A` is the number of aspect ratios to generate additional anchor boxes.\n",
        "\n",
        "### Task description\n",
        "\n",
        "Our aim is to find the maximum number of anchor boxes in varying sizes `feature_szs` and aspect ratios `asp_ratios` across the entire image. We apply no filtering to get rid of low (IOU) anchors.\n",
        "\n",
        "<img src=\"https://lilianweng.github.io/lil-log/assets/images/SSD-framework.png\" width=\"600\" />"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aca26b3f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-15T18:00:27.033141Z",
          "iopub.status.busy": "2022-01-15T18:00:27.032418Z",
          "iopub.status.idle": "2022-01-15T18:00:27.034948Z",
          "shell.execute_reply": "2022-01-15T18:00:27.034375Z",
          "shell.execute_reply.started": "2022-01-15T17:50:58.517734Z"
        },
        "id": "aca26b3f",
        "papermill": {
          "duration": 0.029729,
          "end_time": "2022-01-15T18:00:27.035099",
          "exception": false,
          "start_time": "2022-01-15T18:00:27.005370",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "feature_szs = [(37,37), (18,18), (8,8), (3,3)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f45dec8a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-15T18:00:27.087113Z",
          "iopub.status.busy": "2022-01-15T18:00:27.086341Z",
          "iopub.status.idle": "2022-01-15T18:00:27.089033Z",
          "shell.execute_reply": "2022-01-15T18:00:27.088462Z",
          "shell.execute_reply.started": "2022-01-15T17:50:58.524059Z"
        },
        "id": "f45dec8a",
        "papermill": {
          "duration": 0.033227,
          "end_time": "2022-01-15T18:00:27.089177",
          "exception": false,
          "start_time": "2022-01-15T18:00:27.055950",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "asp_ratios = [1/2., 1., 2.]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07049cce",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-15T18:00:27.138756Z",
          "iopub.status.busy": "2022-01-15T18:00:27.137815Z",
          "iopub.status.idle": "2022-01-15T18:00:27.141964Z",
          "shell.execute_reply": "2022-01-15T18:00:27.142526Z",
          "shell.execute_reply.started": "2022-01-15T17:50:58.536683Z"
        },
        "id": "07049cce",
        "papermill": {
          "duration": 0.03305,
          "end_time": "2022-01-15T18:00:27.142765",
          "exception": false,
          "start_time": "2022-01-15T18:00:27.109715",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "from operator import __mul__\n",
        "n_boxes = sum([__mul__(*f) for f in feature_szs]) \n",
        "print(f'minimum anchor boxes with 1 aspect ratio: {n_boxes}')\n",
        "print(f'minimum anchor boxes with {len(asp_ratios)} aspect ratios: {n_boxes*len(asp_ratios)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd59928b",
      "metadata": {
        "id": "cd59928b",
        "papermill": {
          "duration": 0.021216,
          "end_time": "2022-01-15T18:00:27.185571",
          "exception": false,
          "start_time": "2022-01-15T18:00:27.164355",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Loading an image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43bd5786",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-15T18:00:27.234280Z",
          "iopub.status.busy": "2022-01-15T18:00:27.233506Z",
          "iopub.status.idle": "2022-01-15T18:00:27.237653Z",
          "shell.execute_reply": "2022-01-15T18:00:27.237065Z",
          "shell.execute_reply.started": "2022-01-15T17:50:58.548577Z"
        },
        "id": "43bd5786",
        "papermill": {
          "duration": 0.031417,
          "end_time": "2022-01-15T18:00:27.237814",
          "exception": false,
          "start_time": "2022-01-15T18:00:27.206397",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70f2cd48",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-15T18:00:27.288229Z",
          "iopub.status.busy": "2022-01-15T18:00:27.287472Z",
          "iopub.status.idle": "2022-01-15T18:00:27.586666Z",
          "shell.execute_reply": "2022-01-15T18:00:27.587184Z",
          "shell.execute_reply.started": "2022-01-15T17:50:58.56001Z"
        },
        "id": "70f2cd48",
        "papermill": {
          "duration": 0.328678,
          "end_time": "2022-01-15T18:00:27.587377",
          "exception": false,
          "start_time": "2022-01-15T18:00:27.258699",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "im = Image.open(\"image.jpg\").convert('RGB').resize([300,300])\n",
        "_ = plt.imshow(im)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8cf3e01",
      "metadata": {
        "id": "a8cf3e01",
        "papermill": {
          "duration": 0.024124,
          "end_time": "2022-01-15T18:00:27.634480",
          "exception": false,
          "start_time": "2022-01-15T18:00:27.610356",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "We also make 2 truth bounding boxes `bbox` for this image around the clock and the photoframe in `pascal voc` format:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f70fb639",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-15T18:00:27.686393Z",
          "iopub.status.busy": "2022-01-15T18:00:27.685704Z",
          "iopub.status.idle": "2022-01-15T18:00:27.692496Z",
          "shell.execute_reply": "2022-01-15T18:00:27.693137Z",
          "shell.execute_reply.started": "2022-01-15T17:51:00.308247Z"
        },
        "id": "f70fb639",
        "papermill": {
          "duration": 0.03505,
          "end_time": "2022-01-15T18:00:27.693319",
          "exception": false,
          "start_time": "2022-01-15T18:00:27.658269",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "bbox = [dict(x_min=150, y_min=70, x_max=270, y_max=220, label='clock'),\n",
        "        dict(x_min=10, y_min=180, x_max=115, y_max=260, label='frame'),]\n",
        "bbox"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14a20b85",
      "metadata": {
        "id": "14a20b85",
        "papermill": {
          "duration": 0.022688,
          "end_time": "2022-01-15T18:00:27.740432",
          "exception": false,
          "start_time": "2022-01-15T18:00:27.717744",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "Save annotations as a json file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec071141",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-15T18:00:27.792021Z",
          "iopub.status.busy": "2022-01-15T18:00:27.791162Z",
          "iopub.status.idle": "2022-01-15T18:00:27.795691Z",
          "shell.execute_reply": "2022-01-15T18:00:27.796356Z",
          "shell.execute_reply.started": "2022-01-15T17:51:00.968052Z"
        },
        "id": "ec071141",
        "papermill": {
          "duration": 0.032885,
          "end_time": "2022-01-15T18:00:27.796558",
          "exception": false,
          "start_time": "2022-01-15T18:00:27.763673",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "with open('annots.json', 'w') as f:\n",
        "  f.write(json.dumps(bbox))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6f0077f",
      "metadata": {
        "id": "f6f0077f",
        "papermill": {
          "duration": 0.022644,
          "end_time": "2022-01-15T18:00:27.842466",
          "exception": false,
          "start_time": "2022-01-15T18:00:27.819822",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Using PyBx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f18f544",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-15T18:00:27.893224Z",
          "iopub.status.busy": "2022-01-15T18:00:27.891819Z",
          "iopub.status.idle": "2022-01-15T18:00:28.475204Z",
          "shell.execute_reply": "2022-01-15T18:00:28.474369Z",
          "shell.execute_reply.started": "2022-01-15T17:51:01.782431Z"
        },
        "id": "4f18f544",
        "papermill": {
          "duration": 0.609979,
          "end_time": "2022-01-15T18:00:28.475425",
          "exception": false,
          "start_time": "2022-01-15T18:00:27.865446",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "from pybx import anchor\n",
        "\n",
        "image_sz = (300, 300, 3)  # W, H, C\n",
        "feature_sz = (3, 3)       # number of features along W, H\n",
        "asp_ratio = 1.            # aspect ratio of the anchor box\n",
        "\n",
        "anchors, labels = anchor.bx(image_sz, feature_sz, asp_ratio)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To visualize the anchors:"
      ],
      "metadata": {
        "id": "EXuXNLjfGELR"
      },
      "id": "EXuXNLjfGELR"
    },
    {
      "cell_type": "code",
      "source": [
        "from pybx import vis\n",
        "\n",
        "v = vis.VisBx(image_sz)\n",
        "v.show(anchors, labels)"
      ],
      "metadata": {
        "id": "CQ5vnwYxGF0P"
      },
      "id": "CQ5vnwYxGF0P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "aff410bf",
      "metadata": {
        "id": "aff410bf",
        "papermill": {
          "duration": 0.032702,
          "end_time": "2022-01-15T18:00:28.538763",
          "exception": false,
          "start_time": "2022-01-15T18:00:28.506061",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "The boxes in white are the anchor boxes. We can hightlight them with a different color by looking up specific box labels."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "anchors.shape, labels"
      ],
      "metadata": {
        "id": "IWD8Q-kNGVfU"
      },
      "id": "IWD8Q-kNGVfU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see there are 16 labels and box coordinates reported by `anchor.bx()`, but we are certain that there are only 9 anchor boxes possible for our `feature_sz=3x3` and single `asp_ratio`. Out of the 16 calculated by `anchor.bx()`, 7 of them are considered `invalid` (they are not true anchor boxes) by `pybx` and are not shown or taken into account during further processing. `anchor.bx` in `v0.1.3` preserves them and their labels, but does not use them for calculations or visualisation, once instantiated as a `MultiBx`. To wrap a set of coordinates as `MultiBx`, we can use the `mbx()` method. "
      ],
      "metadata": {
        "id": "tP3u48UtGYMZ"
      },
      "id": "tP3u48UtGYMZ"
    },
    {
      "cell_type": "code",
      "source": [
        "from pybx.basics import *\n",
        "\n",
        "b = mbx(anchors, labels)  # instantiates MultiBx for us"
      ],
      "metadata": {
        "id": "j0UIn9crIGhu"
      },
      "id": "j0UIn9crIGhu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(b)"
      ],
      "metadata": {
        "id": "naYNwM2glCXS"
      },
      "id": "naYNwM2glCXS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can iterate over a `MultiBx` object using list comprehension to understand the internal checks:"
      ],
      "metadata": {
        "id": "_6r36yD0I63O"
      },
      "id": "_6r36yD0I63O"
    },
    {
      "cell_type": "code",
      "source": [
        "[(i, b_.valid()) for i, b_ in enumerate(b)]  # only valid boxes shown"
      ],
      "metadata": {
        "id": "Z9hMXGCqItdj"
      },
      "id": "Z9hMXGCqItdj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`b_.valid()` returned `True` meaning that the box is considered valid. \n",
        "\n",
        "We can also calculate the areas of these boxes."
      ],
      "metadata": {
        "id": "-86Sb7XgMFMm"
      },
      "id": "-86Sb7XgMFMm"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each box `b_` of the `MultiBx` b is of type `BaseBx` which has some additional methods."
      ],
      "metadata": {
        "id": "3IrS93WdlcqA"
      },
      "id": "3IrS93WdlcqA"
    },
    {
      "cell_type": "code",
      "source": [
        "[b_.area() for b_ in b] "
      ],
      "metadata": {
        "id": "cNndZSKRIwTu"
      },
      "id": "cNndZSKRIwTu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Displaying the coordinates of the valid boxes:"
      ],
      "metadata": {
        "id": "WbpnuFiYMcEc"
      },
      "id": "WbpnuFiYMcEc"
    },
    {
      "cell_type": "code",
      "source": [
        "[b_.coords for b_ in b]  # selected boxes only!"
      ],
      "metadata": {
        "id": "H9xNlXqNI0zF"
      },
      "id": "H9xNlXqNI0zF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Displaying the labels of valid boxes"
      ],
      "metadata": {
        "id": "6YLj06rglT18"
      },
      "id": "6YLj06rglT18"
    },
    {
      "cell_type": "code",
      "source": [
        "[b_.label for b_ in b]  # selected boxes only!"
      ],
      "metadata": {
        "id": "5jcrwsljlQ-A"
      },
      "id": "5jcrwsljlQ-A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can ofcourse see all the 16 boxes calculated by `anchor.bx()` from the `MultiBx` as well:"
      ],
      "metadata": {
        "id": "DzIGBgxdJsoP"
      },
      "id": "DzIGBgxdJsoP"
    },
    {
      "cell_type": "code",
      "source": [
        "b.coords, b.label"
      ],
      "metadata": {
        "id": "jS8o0sLTJsLL"
      },
      "id": "jS8o0sLTJsLL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> The `vis.VisBx` internally converts all coordinates in list/json/ndarray to a `MultiBx` and shows only `valid` boxes. \n",
        "\n",
        "We can also overlay the features generated by the model on the original image. `logits=True` generates random logits (`np.random.randn`) of the same shape as feature sizes for illustration purposes. \n",
        "\n",
        "To aid the explainability of the model, actual model logits can also be passed into the same parameter as an array or detached tensor."
      ],
      "metadata": {
        "id": "tHvfzubiJTnR"
      },
      "id": "tHvfzubiJTnR"
    },
    {
      "cell_type": "code",
      "source": [
        "# ask VisBx to use random logits with logits=True\n",
        "vis.VisBx(image_sz, logits=True, feature_sz=feature_sz).show(anchors, labels)"
      ],
      "metadata": {
        "id": "kL4LFB__Dny_"
      },
      "id": "kL4LFB__Dny_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ask VisBx to use passed logits with logits=logits\n",
        "logits = np.random.randn(3,3)  # assuming these are model logits\n",
        "v = vis.VisBx(image_sz, logits=logits).show(anchors, labels)"
      ],
      "metadata": {
        "id": "c_48pnKGKhiW"
      },
      "id": "c_48pnKGKhiW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can hightlight them with a different color if needed. Anchor boxes generated with `named=True` parameter automatically sets the label for each box in the format: `{anchor_sfx}_{feature_sz}_{asp_ratio}_{box_number}`. `anchor_sfx` is also an optional parameter that can be passed to `anchor.bx()`. Here we change the color of one anchor box and one ground truth box."
      ],
      "metadata": {
        "id": "z9_v0f05LLSx"
      },
      "id": "z9_v0f05LLSx"
    },
    {
      "cell_type": "code",
      "source": [
        "labels[4]"
      ],
      "metadata": {
        "id": "8MvvkIsyD8w9"
      },
      "id": "8MvvkIsyD8w9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v = vis.VisBx(image_sz)\n",
        "v.show(anchors, labels, color={'a_3x3_0.5_4':'red', 'clock':'orange'})"
      ],
      "metadata": {
        "id": "l0rx9RcODzsz"
      },
      "id": "l0rx9RcODzsz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "a6b699aa",
      "metadata": {
        "id": "a6b699aa",
        "papermill": {
          "duration": 0.030927,
          "end_time": "2022-01-15T18:00:29.751836",
          "exception": false,
          "start_time": "2022-01-15T18:00:29.720909",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Working with mulitple feature sizes and aspect ratios\n",
        "Finally we calculate anchor boxes for multiple feature sizes and aspect ratios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89e5abf3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-15T18:00:29.819942Z",
          "iopub.status.busy": "2022-01-15T18:00:29.818489Z",
          "iopub.status.idle": "2022-01-15T18:00:31.452954Z",
          "shell.execute_reply": "2022-01-15T18:00:31.453477Z",
          "shell.execute_reply.started": "2022-01-15T17:51:05.334974Z"
        },
        "id": "89e5abf3",
        "papermill": {
          "duration": 1.670961,
          "end_time": "2022-01-15T18:00:31.453682",
          "exception": false,
          "start_time": "2022-01-15T18:00:29.782721",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "feature_szs = [(3, 3), (2, 2)]\n",
        "asp_ratios = [1/2., 2.]\n",
        "\n",
        "anchors, labels = anchor.bxs(image_sz, feature_szs, asp_ratios)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e545a09c",
      "metadata": {
        "id": "e545a09c",
        "papermill": {
          "duration": 0.03994,
          "end_time": "2022-01-15T18:00:31.535833",
          "exception": false,
          "start_time": "2022-01-15T18:00:31.495893",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "This is essentially a wrapper to do list comprehension over the passed feature sizes and aspect ratios (but additionally stacks them together into an ndarray).\n",
        "\n",
        "```\n",
        "[anchor.bx(image_sz, f, ar) for f in feature_szs for ar in asp_ratios]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels[4], labels[32]"
      ],
      "metadata": {
        "id": "MyLwmBJFEQcn"
      },
      "id": "MyLwmBJFEQcn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v = vis.VisBx(image_sz)\n",
        "v.show(anchors, labels, color={'a_3x3_0.5_4':'red', 'a_2x2_0.5_0':'red'})"
      ],
      "metadata": {
        "id": "XoGYx-1JEK42"
      },
      "id": "XoGYx-1JEK42",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "3fc162f5",
      "metadata": {
        "id": "3fc162f5",
        "papermill": {
          "duration": 0.039163,
          "end_time": "2022-01-15T18:00:31.616485",
          "exception": false,
          "start_time": "2022-01-15T18:00:31.577322",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "As simple as that! Do leave a star or raise issues and suggestions on the project page if you found this useful! \n",
        "\n",
        "Project page: [GitHub](https://github.com/thatgeeman/pybx) \n",
        "\n",
        "PyPi Package: [PyBx](https://pypi.org/project/pybx/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6bf2f62",
      "metadata": {
        "papermill": {
          "duration": 0.039503,
          "end_time": "2022-01-15T18:00:31.698358",
          "exception": false,
          "start_time": "2022-01-15T18:00:31.658855",
          "status": "completed"
        },
        "tags": [],
        "id": "a6bf2f62"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 34.691937,
      "end_time": "2022-01-15T18:00:32.454202",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2022-01-15T17:59:57.762265",
      "version": "2.3.3"
    },
    "colab": {
      "name": "pybx_walkthrough.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}