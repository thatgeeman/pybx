[
  {
    "objectID": "anchor.html",
    "href": "anchor.html",
    "title": "Generate anchor boxes",
    "section": "",
    "text": "To generate anchor boxes, we need three basic information:\n\nInput image size, image_sz: To position our anchor boxes within the maximum coordinates (width, height) of the image.\nFeature map size, feature_sz: Feature map is the size (width, height) of the output of a convolutional operation. A \\(10\\times10\\) feature map would mean \\(10\\times10\\) local receptive field locations can be traced back into the input image. These 100 receptive field locations (\\(10\\times10=100\\)) in the input image would act as our initial anchor box candidates.\n\n\n\nAspect ratio of anchor boxes, asp_ratio: To generate anchor boxes with different width to height ratio (default asp_ratio=1).\n\n\nsource\n\nbx\n\n bx (image_sz:(<class'int'>,<class'tuple'>),\n     feature_sz:(<class'int'>,<class'tuple'>), asp_ratio:float=None,\n     clip:bool=True, named:bool=True, anchor_sfx:str='a',\n     min_visibility:float=0.25)\n\nCalculate anchor box coords given an image size and feature size for a single aspect ratio.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nimage_sz\n(<class ‘int’>, <class ‘tuple’>)\n\nimage size (width, height)\n\n\nfeature_sz\n(<class ‘int’>, <class ‘tuple’>)\n\nfeature map size (width, height)\n\n\nasp_ratio\nfloat\nNone\naspect ratio (width:height), by default None\n\n\nclip\nbool\nTrue\nwhether to apply np.clip, by default True\n\n\nnamed\nbool\nTrue\nwhether to return (coords, labels), by default True\n\n\nanchor_sfx\nstr\na\nsuffix anchor label with anchor_sfx, by default “a”\n\n\nmin_visibility\nfloat\n0.25\nminimum visibility dictates the condition for a box to be consideredvalid. The value corresponds to the ratio of expected area of an anchor boxto the calculated area after clipping to image dimensions., by default 0.25\n\n\nReturns\ntyping.Union[typing.Sequence[typing.Sequence[typing.Sequence[typing.Sequence[typing.Sequence[typing.Any]]]]], numpy.typing._array_like._SupportsArray[numpy.dtype], typing.Sequence[numpy.typing._array_like._SupportsArray[numpy.dtype]], typing.Sequence[typing.Sequence[numpy.typing._array_like._SupportsArray[numpy.dtype]]], typing.Sequence[typing.Sequence[typing.Sequence[numpy.typing._array_like._SupportsArray[numpy.dtype]]]], typing.Sequence[typing.Sequence[typing.Sequence[typing.Sequence[numpy.typing._array_like._SupportsArray[numpy.dtype]]]]], bool, int, float, complex, str, bytes, typing.Sequence[typing.Union[bool, int, float, complex, str, bytes]], typing.Sequence[typing.Sequence[typing.Union[bool, int, float, complex, str, bytes]]], typing.Sequence[typing.Sequence[typing.Sequence[typing.Union[bool, int, float, complex, str, bytes]]]], typing.Sequence[typing.Sequence[typing.Sequence[typing.Sequence[typing.Union[bool, int, float, complex, str, bytes]]]]]]\n\nanchor box coordinates in pascal_voc formatif named=True, a list of anchor box labels are also returned.\n\n\n\n\ncoords_1, labels_1 = bx(100, 10, 0.5)\n\n\ncoords_1\n\n[[1, 0, 8, 12],\n [11, 0, 18, 12],\n [21, 0, 28, 12],\n [31, 0, 38, 12],\n [41, 0, 48, 12],\n [51, 0, 58, 12],\n [61, 0, 68, 12],\n [71, 0, 78, 12],\n [81, 0, 88, 12],\n [91, 0, 98, 12],\n [1, 7, 8, 22],\n [11, 7, 18, 22],\n [21, 7, 28, 22],\n [31, 7, 38, 22],\n [41, 7, 48, 22],\n [51, 7, 58, 22],\n [61, 7, 68, 22],\n [71, 7, 78, 22],\n [81, 7, 88, 22],\n [91, 7, 98, 22],\n [1, 17, 8, 32],\n [11, 17, 18, 32],\n [21, 17, 28, 32],\n [31, 17, 38, 32],\n [41, 17, 48, 32],\n [51, 17, 58, 32],\n [61, 17, 68, 32],\n [71, 17, 78, 32],\n [81, 17, 88, 32],\n [91, 17, 98, 32],\n [1, 27, 8, 42],\n [11, 27, 18, 42],\n [21, 27, 28, 42],\n [31, 27, 38, 42],\n [41, 27, 48, 42],\n [51, 27, 58, 42],\n [61, 27, 68, 42],\n [71, 27, 78, 42],\n [81, 27, 88, 42],\n [91, 27, 98, 42],\n [1, 37, 8, 52],\n [11, 37, 18, 52],\n [21, 37, 28, 52],\n [31, 37, 38, 52],\n [41, 37, 48, 52],\n [51, 37, 58, 52],\n [61, 37, 68, 52],\n [71, 37, 78, 52],\n [81, 37, 88, 52],\n [91, 37, 98, 52],\n [1, 47, 8, 62],\n [11, 47, 18, 62],\n [21, 47, 28, 62],\n [31, 47, 38, 62],\n [41, 47, 48, 62],\n [51, 47, 58, 62],\n [61, 47, 68, 62],\n [71, 47, 78, 62],\n [81, 47, 88, 62],\n [91, 47, 98, 62],\n [1, 57, 8, 72],\n [11, 57, 18, 72],\n [21, 57, 28, 72],\n [31, 57, 38, 72],\n [41, 57, 48, 72],\n [51, 57, 58, 72],\n [61, 57, 68, 72],\n [71, 57, 78, 72],\n [81, 57, 88, 72],\n [91, 57, 98, 72],\n [1, 67, 8, 82],\n [11, 67, 18, 82],\n [21, 67, 28, 82],\n [31, 67, 38, 82],\n [41, 67, 48, 82],\n [51, 67, 58, 82],\n [61, 67, 68, 82],\n [71, 67, 78, 82],\n [81, 67, 88, 82],\n [91, 67, 98, 82],\n [1, 77, 8, 92],\n [11, 77, 18, 92],\n [21, 77, 28, 92],\n [31, 77, 38, 92],\n [41, 77, 48, 92],\n [51, 77, 58, 92],\n [61, 77, 68, 92],\n [71, 77, 78, 92],\n [81, 77, 88, 92],\n [91, 77, 98, 92],\n [1, 87, 8, 100],\n [11, 87, 18, 100],\n [21, 87, 28, 100],\n [31, 87, 38, 100],\n [41, 87, 48, 100],\n [51, 87, 58, 100],\n [61, 87, 68, 100],\n [71, 87, 78, 100],\n [81, 87, 88, 100],\n [91, 87, 98, 100]]\n\n\nUsually multiple anchor boxes with different feature_sz and asp_ratio are needed. This requirement arises in the case of multiscale object detection.\nFor multiscale object detection, feature maps from different convolution operations of the network are used to trace back into the input image, to generate anchor boxes. The bxs method of pybx provides this possibility.\n\nsource\n\n\nbxs\n\n bxs (image_sz:(<class'int'>,<class'tuple'>), feature_szs:list=None,\n      asp_ratios:list=None, named:bool=True, **kwargs)\n\nCalculate anchor box coords given an image size and multiple feature sizes for mutiple aspect ratios.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nimage_sz\n(<class ‘int’>, <class ‘tuple’>)\n\nimage size (width, height)\n\n\nfeature_szs\nlist\nNone\nlist of feature map sizes, each feature map size being an int or tuple, by default [(8, 8), (2, 2)]\n\n\nasp_ratios\nlist\nNone\nlist of aspect ratios for anchor boxes, each aspect ratio being a float calculated by (width:height), by default [1 / 2.0, 1.0, 2.0]\n\n\nnamed\nbool\nTrue\nwhether to return (coords, labels), by default True\n\n\nkwargs\n\n\n\n\n\nReturns\ntyping.Union[typing.Sequence[typing.Sequence[typing.Sequence[typing.Sequence[typing.Sequence[typing.Any]]]]], numpy.typing._array_like._SupportsArray[numpy.dtype], typing.Sequence[numpy.typing._array_like._SupportsArray[numpy.dtype]], typing.Sequence[typing.Sequence[numpy.typing._array_like._SupportsArray[numpy.dtype]]], typing.Sequence[typing.Sequence[typing.Sequence[numpy.typing._array_like._SupportsArray[numpy.dtype]]]], typing.Sequence[typing.Sequence[typing.Sequence[typing.Sequence[numpy.typing._array_like._SupportsArray[numpy.dtype]]]]], bool, int, float, complex, str, bytes, typing.Sequence[typing.Union[bool, int, float, complex, str, bytes]], typing.Sequence[typing.Sequence[typing.Union[bool, int, float, complex, str, bytes]]], typing.Sequence[typing.Sequence[typing.Sequence[typing.Union[bool, int, float, complex, str, bytes]]]], typing.Sequence[typing.Sequence[typing.Sequence[typing.Sequence[typing.Union[bool, int, float, complex, str, bytes]]]]]]\n\nanchor box coordinates in pascal_voc formatif named=True, a list of anchor box labels are also returned.\n\n\n\n\ncoords, labels = bxs(100, [10, 8, 5, 2], [1, 0.5, 0.3])\n\n\ncoords.shape, len(labels)\n\n((587, 4), 587)\n\n\nAll methods work with asymetric image_sz (and or feature_szs as well):\n\ncoords, labels = bxs((100, 200), [10, 8, 5, 2], [1, 0.5, 0.3])\n\n\ncoords.shape, len(labels)\n\n((654, 4), 654)\n\n\n\n\nGround truth anchor boxes\nGround truth boxes are anchor boxes with maximum IOU with the true annotations.\nLoad actual annotations.\n\ntrue_annots = json.load(open('../data/annots.json'))\ntrue_annots\n\n[{'x_min': 130, 'y_min': 63, 'x_max': 225, 'y_max': 180, 'label': 'clock'},\n {'x_min': 13, 'y_min': 158, 'x_max': 90, 'y_max': 213, 'label': 'frame'}]\n\n\nConvert to MultiBx for convenience:\n\ntrue_annots_as_bx = get_bx(true_annots)\ntrue_annots_as_bx\n\nMultiBx(coords=[[130, 63, 225, 180], [13, 158, 90, 213]], label=['clock', 'frame'])\n\n\nGenerate anchor boxes for object detection task, given that we know:\nimage_sz = (256, 256)  # to know the upper bounds of candidate bounding boxes\nfeature_sz = [20, 10, 8, 3]\nasp_ratio = [1, 0.5, 0.3]\n\ncoords, labels = bxs((256, 256), [20, 10, 8, 3], [1, 0.5, 0.3])\n\n\ncoords.shape, len(labels)\n\n((1741, 4), 1741)\n\n\n\nn_boxes = coords.shape[0]\nn_boxes\n\n1741\n\n\nStore coords as multibx for convenience.\n\ncoords_as_bx = get_bx(coords=coords, label=labels)\n\nCan use the true annotations and anchor boxes to calulate the IOU.\n\ntrue_annots_as_bx\n\nMultiBx(coords=[[130, 63, 225, 180], [13, 158, 90, 213]], label=['clock', 'frame'])\n\n\n\nlen(true_annots_as_bx), len(coords_as_bx)\n\n(2, 1741)\n\n\nThe question: for each true label in the provided true annotations, what are the possible ground truth anchor boxes?\n\nfor annots in true_annots_as_bx:\n    print(annots)\n\nBaseBx(coords=[[130, 63, 225, 180]], label=['clock'])\nBaseBx(coords=[[13, 158, 90, 213]], label=['frame'])\n\n\n\ngt_anchors_per_class = defaultdict(lambda: L())\niou_per_box = defaultdict(lambda: L())\nfor annots in true_annots_as_bx:\n    label = annots.label[0]  # is a list of len 1\n    ious = [annots.iou(coords_as_bx[i]) for i in range(n_boxes)]\n    iou_per_box[label].extend(ious)\n\n\niou_per_box.keys()\n\ndict_keys(['clock', 'frame'])\n\n\n\nmax(iou_per_box['clock'])\n\n0.34822804314329736\n\n\n\niou_per_box['clock'].argwhere(gt(0.3))  # indices of boxes with iou > 0.3\n\n(#2) [1719,1728]\n\n\n\niou_per_box['frame'].argwhere(gt(0.3))  # indices of boxes with iou > 0.3\n\n(#3) [1720,1729,1738]\n\n\n\n(max(iou_per_box['clock'])), max(iou_per_box['frame'])  # add more anchor boxes to get better ground truth IOUs\n\n(0.34822804314329736, 0.4488243430152144)\n\n\nImprove the loop to return only those with good IOU:\n\niou_thresh = 0.3\ngt_anchors_per_class = defaultdict(lambda: L())\niou_per_box = defaultdict(lambda: L())\nfor annots in true_annots_as_bx:\n    label = annots.label[0]  # is a list of len 1\n    ious = L([annots.iou(coords_as_bx[i]) for i in range(n_boxes)])\n    ious_filter = ious.argwhere(gt(iou_thresh))\n    # report filtered box IOUs\n    iou_per_box[label].extend(ious[ious_filter])\n    # report selected boxes\n    gt_anchors_per_class[label] = stack_bxs_inplace(\n        *[coords_as_bx[i] for i in ious_filter]\n    )\n\n\niou_per_box['clock'], iou_per_box['frame']\n\n((#2) [0.34,0.34822804314329736],\n (#3) [0.36643389750266303,0.4488243430152144,0.3523238380809595])\n\n\n\ngt_anchors_per_class['clock']\n\nMultiBx(coords=[[170, 85, 256, 170], [183, 67, 243, 188]], label=['a_3x3_1.0_5', 'a_3x3_0.5_5'])\n\n\nNot very far from the original annotations. These scales and aspect ratios can also be read from the label. The finer the anchor boxes, the better the starting positions (ground truth anchor boxes).\n\ntrue_annots[0]\n\n{'x_min': 130, 'y_min': 63, 'x_max': 225, 'y_max': 180, 'label': 'clock'}\n\n\n\ntmp = L([1, 2, 3])\nmsk = tmp.map(lambda x: x>1)\n\n\ntmp[msk]\n\n(#2) [2,3]\n\n\n\nmask2idxs(msk)\n\n[1, 2]\n\n\n\nsource\n\nget_gt_thresh_iou\n\n get_gt_thresh_iou (true_annots, anchor_boxes, anchor_labels=None,\n                    iou_thresh=0.3, return_ious=False, return_masks=False,\n                    update_labels=True)\n\nCalculate positive ground truth and extra positive ground truth bounding boxes based on iou threhsold.\nCan result in uneven number of positive ground truth boxes per class.\nArgs: true_annots (Any): True annotations, typically in pascal_voc format anchor_boxes (Any): Candidate anchor boxes, typically calculated with pybx.bxs anchor_labels (List, optional): Anchor box labels, will be overwritten with true labels if update_labels=True. Defaults to None. iou_thresh (float, optional): IOU threshold to filter out negative ground truth anchor boxes. Defaults to 0.3. return_ious (bool, optional): Return IOU values for selected positive ground truth anchor boxes. Defaults to False. return_masks (bool, optional): Return boolean masks for all anchor boxes indicating if a box is positive (True) or negative (False) ground truth box. Defaults to False. update_labels (bool, optional): Overwrite with true annotations. Defaults to True.\nReturns: dict: positive ground truth anchor boxes per class dict: IOU of positive ground truth anchor boxes per class dict: boolean list indicating positive ground truth anchor boxes per class\n\ncoords\n\narray([[  0,   0,  12,  12],\n       [ 12,   0,  25,  12],\n       [ 25,   0,  38,  12],\n       ...,\n       [ 19, 135,  66, 256],\n       [104, 135, 151, 256],\n       [189, 135, 236, 256]])\n\n\n\ngt_anchors_per_class, ious_per_class, mask_per_class = get_gt_thresh_iou(true_annots, coords, iou_thresh=0.3, return_ious=True)\ngt_anchors_per_class\n\n{'clock': MultiBx(coords=[[170, 85, 256, 170], [183, 67, 243, 188]], label=['clock', 'clock']),\n 'frame': MultiBx(coords=[[0, 170, 85, 256], [12, 152, 72, 256], [19, 135, 66, 256]], label=['frame', 'frame', 'frame'])}\n\n\n\nmask_per_class\n\n{}\n\n\n\ntrue_annots\n\n[{'x_min': 130, 'y_min': 63, 'x_max': 225, 'y_max': 180, 'label': 'clock'},\n {'x_min': 13, 'y_min': 158, 'x_max': 90, 'y_max': 213, 'label': 'frame'}]\n\n\n\nious_per_class['clock']\n\n(#2) [0.34,0.3482]\n\n\n\ngt_anchors_per_class['clock'].coords\n\n[[170, 85, 256, 170], [183, 67, 243, 188]]\n\n\nIf anchor box labels are passed, they can be preserved instead of overwriting with ground truth labels.\n\nget_gt_thresh_iou([100, 150, 180, 300, 'hat'], coords, iou_thresh=0.3, anchor_labels=labels, update_labels=False, return_ious=True)\n\n({'hat': MultiBx(coords=[[85, 170, 170, 256], [97, 152, 158, 256], [104, 135, 151, 256]], label=['a_3x3_1.0_7', 'a_3x3_0.5_7', 'a_3x3_0.3_7'])},\n {'hat': (#3) [0.453,0.4899,0.3921]},\n {})\n\n\nTrue annots can also be a list containing the label as the last item.\n\nget_gt_thresh_iou([100, 150, 180, 300, 'hat'], coords, iou_thresh=0.3, return_ious=True)\n\n({'hat': MultiBx(coords=[[85, 170, 170, 256], [97, 152, 158, 256], [104, 135, 151, 256]], label=['hat', 'hat', 'hat'])},\n {'hat': (#3) [0.453,0.4899,0.3921]},\n {})\n\n\n\nget_gt_thresh_iou([[100, 150, 180, 300, 'hat'], [100, 120, 280, 200, 'shirt']], coords, iou_thresh=0.3, return_ious=True)\n\n/mnt/data/projects/pybx/.venv/lib/python3.7/site-packages/ipykernel_launcher.py:59: NoGroundTruthBxs: No good ground truth anchors found for label=shirt, try lowering threshold (iou_thresh=0.3 or increasing candidates.\n\n\n({'hat': MultiBx(coords=[[85, 170, 170, 256], [97, 152, 158, 256], [104, 135, 151, 256]], label=['hat', 'hat', 'hat']),\n  'shirt': None},\n {'hat': (#3) [0.453,0.4899,0.3921], 'shirt': (#0) []},\n {})\n\n\nMethod to also return just the max IOU ground truth boxes.\n\nsource\n\n\nget_gt_max_iou\n\n get_gt_max_iou (true_annots, anchor_boxes, anchor_labels=None,\n                 return_ious=False, return_masks=False, positive_boxes=1,\n                 update_labels=True)\n\nCalculate positive ground truth and extra positive ground truth bounding boxes based on maximum IOU condition.\nWill always provide a box, therfore constant number positive_boxes of positive ground truth boxes per class.\nArgs: true_annots (Any): True annotations, typically in pascal_voc format anchor_boxes (Any): Candidate anchor boxes, typically calculated with pybx.bxs anchor_labels (List, optional): Anchor box labels, will be overwritten with true labels if update_labels=True. Defaults to None. return_ious (bool, optional): Return IOU values for selected positive ground truth anchor boxes. Defaults to False. return_masks (bool, optional): Return boolean masks for all anchor boxes indicating if a box is positive (True) or negative (False) ground truth box. Defaults to False. update_labels (bool, optional): Overwrite with true annotations. Defaults to True. positive_boxes (int, optional): Number of extra/positive ground truth boxes to return. Defaults to 1.\nReturns: dict: positive ground truth anchor boxes per class dict: IOU of positive ground truth anchor boxes per class dict: boolean list indicating positive ground truth anchor boxes per class\n\nget_gt_max_iou(true_annots, coords)\n\n({'clock': MultiBx(coords=[[183, 67, 243, 188]], label=['clock']),\n  'frame': MultiBx(coords=[[12, 152, 72, 256]], label=['frame'])},\n {},\n {})\n\n\nCan also use methods for the box to calculate properties or convert to different box formats.\n\ntmp_bx = get_gt_max_iou(true_annots, coords)[0]['clock']\ntmp_bx[0]\n\nBaseBx(coords=[[183, 67, 243, 188]], label=['clock'])\n\n\n\ntmp_bx[0].xywh\n\n(#1) [[183, 67, 60, 121]]\n\n\n\ntmp_bx[0].yolo(w=300, h=300, normalize=False)  # cx, cy, bw, bh\n\n(#1) [[0.71, 0.425, 0.2, 0.4033]]\n\n\n\n# here w h is the image w and h\ntmp_bx[0].yolo(w=300, h=300, normalize=True)  # cx/w, cy/h, bw/w, bh/h\n\n(#1) [[0.71, 0.425, 0.2, 0.4033]]\n\n\n\nnp.round([0.4046875, 0.840625, 0.503125, 0.24375], 4)\n\narray([0.4047, 0.8406, 0.5031, 0.2438])\n\n\n\ntrue_annots\n\n[{'x_min': 130, 'y_min': 63, 'x_max': 225, 'y_max': 180, 'label': 'clock'},\n {'x_min': 13, 'y_min': 158, 'x_max': 90, 'y_max': 213, 'label': 'frame'}]\n\n\n\ngt_anchors_per_class, ious_per_class, mask_per_class = get_gt_max_iou(\n    true_annots,\n    coords,\n    return_ious=True,\n    return_masks=True,\n    positive_boxes=1,  # number of positive bounding boxes to allow\n)\ngt_anchors_per_class, ious_per_class, mask_per_class\n\n({'clock': MultiBx(coords=[[183, 67, 243, 188]], label=['clock']),\n  'frame': MultiBx(coords=[[12, 152, 72, 256]], label=['frame'])},\n {'clock': (#1) [0.3482], 'frame': (#1) [0.4488]},\n {'clock': (#1741) [False,False,False,False,False,False,False,False,False,False...],\n  'frame': (#1741) [False,False,False,False,False,False,False,False,False,False...]})\n\n\nVocabulary: - Ground truth bounding box - Ground truth anchor box or positive anchor box - Negative anchor box - Offset is calculated as ground truth bounding box minus positive anchor box coordinates (not for all anchor boxes, use mask) - Normalized offsets\n\n\n\nCalculate offsets for ground truth anchor boxes\nBaseBx also supports calculation of bounding box offset by calling the get_offset() method.\n\nmask_per_class\n\n{'clock': (#1741) [False,False,False,False,False,False,False,False,False,False...],\n 'frame': (#1741) [False,False,False,False,False,False,False,False,False,False...]}\n\n\n\ngt_anchors_per_class\n\n{'clock': MultiBx(coords=[[183, 67, 243, 188]], label=['clock']),\n 'frame': MultiBx(coords=[[12, 152, 72, 256]], label=['frame'])}\n\n\n\ntrue_annots_bx = get_bx(true_annots)\ntrue_annots_bx\n\nMultiBx(coords=[[130, 63, 225, 180], [13, 158, 90, 213]], label=['clock', 'frame'])\n\n\n\ngt_anchors_per_class['clock']\n\nMultiBx(coords=[[183, 67, 243, 188]], label=['clock'])\n\n\n\ngt_anchors_per_class['clock']  # this is still a MultiBx\n\nMultiBx(coords=[[183, 67, 243, 188]], label=['clock'])\n\n\n\nlen(gt_anchors_per_class['clock'])\n\n1\n\n\n\ngt_anchors_per_class['clock'][0]  # this is a BaseBx, which wont raise a warning\n\nBaseBx(coords=[[183, 67, 243, 188]], label=['clock'])\n\n\n\ntrue_annots_bx[0].get_offset(gt_anchors_per_class['clock'])\n\n/mnt/data/projects/pybx/pybx/basics.py:577: BxViolation: Other should be BaseBx, got MultiBx\n  warnings.warn(BxViolation(f\"Other should be BaseBx, got MultiBx\"))\n\n\n(#4) [-5.9167,-0.4959,2.2977,-0.1681]\n\n\n\ntrue_annots_bx[0].get_offset(gt_anchors_per_class['clock'][0])  # by default normalize=True\n\n(#4) [-5.9167,-0.4959,2.2977,-0.1681]\n\n\nWith normalize=False, it calculates simple difference between centers (dcx, dcy) and ratio of width and heights log(w'/w), log(h'/h) the two boxes.\n\ntrue_annots_bx[0].get_offset(gt_anchors_per_class['clock'][0], normalize=False)  #\n\n(#4) [-35.5,-6.0,95.0,117.0]\n\n\nThe following helper function repeats the same operation for multiple boxes, provided the masks (so that only ground truch anchor box offsets are calculated)\n\nsource\n\nget_gt_offsets\n\n get_gt_offsets (true_annots:pybx.basics.BaseBx, anchor_boxes,\n                 anchor_labels=None, masks=None, sigma=(0.1, 0.2),\n                 normalize=True, log_func=<ufunc 'log'>,\n                 update_labels=False)\n\nCalculates the offset of the true annotations from the anchor boxes using the get_offset method of BaseBx.\nArgs: true_annots (Any): True annotation for a single object, typically in pascal_voc format anchor_boxes (Any): Candidate anchor boxes, typically calculated with pybx.bxs anchor_labels (List, optional): Anchor box labels, will be overwritten with ground truth labels if update_labels=True. Defaults to None. masks (List, optional): Anchor box masks indicating if a box is positive/negative anchor box. If nothing is passed, offsets are calculated for all anchor boxes passed. Defaults to None. sigma (tuple, optional): Estimated of standard deviation for the distances and ratios. Defaults to (0.1, 0.2). normalize (bool, optional): Whether to normalize the offsets using the methods used in the SSD paper. Defaults to True. log_func (func, optional): Function for normalizing the ratio of widths and heights. Defaults to np.log. update_labels (bool, optional): Overwrite positive anchor boxes with object class and negative anchor boxes with background class. Defaults to False.\nReturns: list: List of all anchor box offsets. list: List of corresponding anchor box labels.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntrue_annots\nBaseBx\n\n\n\n\nanchor_boxes\n\n\n\n\n\nanchor_labels\nNoneType\nNone\ndo we need to pass this\n\n\nmasks\nNoneType\nNone\n\n\n\nsigma\ntuple\n(0.1, 0.2)\n\n\n\nnormalize\nbool\nTrue\n\n\n\nlog_func\nufunc\nlog\n\n\n\nupdate_labels\nbool\nFalse\n\n\n\n\nThe Ground truth bounding boxes should ideally be passed in as a BaseBx, or will attempt a conversion to BaseBx.\n\ntrue_annots_bx[0]\n\nBaseBx(coords=[[130, 63, 225, 180]], label=['clock'])\n\n\n\ntrue_annots[0]\n\n{'x_min': 130, 'y_min': 63, 'x_max': 225, 'y_max': 180, 'label': 'clock'}\n\n\n\n# passing dict\ngt_offsets_clock, labels = get_gt_offsets(true_annots[0], coords, masks=mask_per_class['clock'])\ngt_offsets_clock[mask_per_class['clock']]  # using the mask to look at only the valid offset\n\narray([[-5.9167, -0.4959,  2.2977, -0.1681]])\n\n\n\n# passing list\ngt_offsets_clock, labels = get_gt_offsets([130, 63, 225, 180, 'clock'], coords, masks=mask_per_class['clock'])\ngt_offsets_clock[mask_per_class['clock']]\n\narray([[-5.9167, -0.4959,  2.2977, -0.1681]])\n\n\nUpdating the labels of the candidates to actual ground truth class labels might be a nice addition as well.\n\ngt_offsets_clock, labels = get_gt_offsets(true_annots[0], coords, masks=mask_per_class['clock'], update_labels=False) \nlabels.unique()\n\n(#1) ['background']\n\n\n\ngt_offsets_clock, labels = get_gt_offsets(true_annots[0], coords, masks=mask_per_class['clock'], update_labels=True) \nlabels.unique()\n\n(#2) ['background','clock']\n\n\nIf no ground truth label is passed with update_labels=True, then unknown is assigned. Doesn’t work with dicts.\n\ngt_offsets_clock, labels = get_gt_offsets([130, 63, 225, 180], coords, masks=mask_per_class['clock'], update_labels=True) \nlabels.unique()\n\n(#2) ['background','unknown']\n\n\n\ngt_offsets_clock[:, 0]\n\narray([0., 0., 0., ..., 0., 0., 0.])\n\n\n\ngt_offsets_clock[mask_per_class['clock']]  # czan use the mask to index the only valid offset\n\narray([[-5.9167, -0.4959,  2.2977, -0.1681]])\n\n\nThe log of widths and heights can be skipped or modified if a different log_func is passed log(w'/w), log(h'/h).\n\nfrom fastcore.foundation import noop  # do no operation, basically an identity function f(x) = x\n\n\ngt_offsets_clock_nolog, _ = get_gt_offsets(true_annots_bx[0], coords, masks=mask_per_class['clock'], log_func=noop) \ngt_offsets_clock_nolog[mask_per_class['clock']]\n\narray([[-5.9167, -0.4959,  7.9167,  4.8347]])\n\n\nOr a custom funciton.\n\ngt_offsets_clock_nolog, _ = get_gt_offsets(true_annots_bx[0], coords, masks=mask_per_class['clock'], log_func=lambda x: x * np.log2(x)) \ngt_offsets_clock_nolog[mask_per_class['clock']]\n\narray([[-5.9167, -0.4959,  5.2485, -0.2345]])\n\n\nRepeating the same operations for all classes.\n\nfor idx, true_bx in enumerate(true_annots_bx):\n    get_gt_offsets(true_bx, coords, masks=mask_per_class[true_bx.label[0]])\n\n\ntrue_annots_bx\n\nMultiBx(coords=[[130, 63, 225, 180], [13, 158, 90, 213]], label=['clock', 'frame'])\n\n\nIf a mask is not provided, offsets are calculated for all anchors, which makes the process slow.\n\nget_gt_offsets(true_annots_bx[0], coords) # without mask\n\n138 ms ± 309 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n\n\n\nget_gt_offsets(true_annots_bx[0], coords, masks=mask_per_class['clock']) # with mask\n\n340 µs ± 11.9 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)"
  },
  {
    "objectID": "basics.html",
    "href": "basics.html",
    "title": "Basic objects",
    "section": "",
    "text": "import json\nfrom fastcore.test import test_eq, test_fail, test_warns, ExceptionExpected\n\nAnchor box coordinates of type list/dict/json/array can be converted to a Bx instance. Once wrapped as a Bx instance, some interesting properties can be calculated from the coordinates.\n\nsource\n\nBx\n\n Bx (coords, label:list=None)\n\nInterface for all future Bx’s\nInitializing an empty Bx class. It does a whole lot of things!\nGenerate random coordinates for one anchor boxes.\n\nnp.random.seed(42)\nannots = [sorted([np.random.randint(100) for i in range(4)])]\nannots\n\n[[14, 51, 71, 92]]\n\n\nIf a single list is passed, Bx will make it a list of list.\n\nBx(annots[0])\n\nBx(coords=[[14, 51, 71, 92]], label=[])\n\n\nSo the correct way to do it would be to pass a list of list.\n\nannots\n\n[[14, 51, 71, 92]]\n\n\n\nb = Bx(annots)\nb\n\nBx(coords=[[14, 51, 71, 92]], label=[])\n\n\n\nlen(b)\n\n1\n\n\n\nb.cx\n\n42.5\n\n\n\nb.yolo\n\n<bound method Bx.yolo of Bx(coords=[[14, 51, 71, 92]], label=[])>\n\n\nTo get normalized coordinates wrt to the image dimensions.\n\nb.yolo(224, 224, normalize=True)\n\n(#1) [[0.1897, 0.3192, 0.2545, 0.183]]\n\n\n\nb.values\n\n(#1) [[14, 51, 71, 92]]\n\n\n\nb.coords_as_numpy\n\narray([[14, 51, 71, 92]])\n\n\nBx is inherited by all other types in pybx: BaseBx, MultiBx, ListBx, JsonBx, exposing the same properties.\nBaseBx works with other types of coordinates too. It accepts the coordinates and label for one anchor box in a list or ndarray format.\n\nsource\n\n\nBaseBx\n\n BaseBx (coords, label:list=None)\n\nBaseBx is the most primitive form of representing a bounding box. Coordinates and label of a bounding box can be wrapped as a BaseBx using: bbx(coords, label).\n:param coords: can be of type list or array representing a single box. - list can be formatted with label: [x_min, y_min, x_max, y_max, label] or without label: [x_min, y_min, x_max, y_max] - array should be a 1-dimensional array of shape (4,)\n:param label: a list or str that has the class name or label for the object in the corresponding box.\nWorks with arrays and lists:\n\nBaseBx(annots)\n\nBaseBx(coords=[[14, 51, 71, 92]], label=[])\n\n\n\nb = BaseBx(annots, 'flower')\n\n\nb\n\nBaseBx(coords=[[14, 51, 71, 92]], label=['flower'])\n\n\n\nb.coords\n\n[[14, 51, 71, 92]]\n\n\n\nb.coords_as_numpy\n\narray([[14, 51, 71, 92]])\n\n\nCalling the values attribute returns the labels along with the coordinates.\n\nb.values\n\n(#1) [[14, 51, 71, 92, 'flower']]\n\n\nBaseBx also exposes a method to calculate the Intersection Over Union (IOU):\n\nsource\n\n\nBaseBx.iou\n\n BaseBx.iou (other)\n\nCaclulates the Intersection Over Union (IOU) of the box w.r.t. another BaseBx. Returns the IOU only if the box is considered valid.\n\nb\n\nBaseBx(coords=[[14, 51, 71, 92]], label=['flower'])\n\n\nBaseBx is also pseudo-iterable (calling an iterator returns self itself and not the coordinates or labels).\n\nb = BaseBx(annots, 'flower')\n\n\nnext(b)\n\nBaseBx(coords=[[14, 51, 71, 92]], label=['flower'])\n\n\n\nfor b_ in b:\n    print(b_)\n\nWorking with multiple bounding boxes and annotaions is usually done with the help of MultiBx. MultiBx allows iteration.\n\nsource\n\n\nMultiBx\n\n MultiBx (coords, label:list=None)\n\nMultiBx represents a collection of bounding boxes as ndarrays. Objects of type MultiBx can be indexed into, which returns a BaseBx exposing a suite of box-bound operations. Multiple coordinates and labels of bounding boxes can be wrapped as a MultiBx using: mbx(coords, label). :param coords: can be nested coordinates of type list of lists/json records (lists of dicts)/ndarrays representing multiple boxes. If passing a list/json each index of the object should be of the following formats: - list can be formatted with label: [x_min, y_min, x_max, y_max, label] or without label: [x_min, y_min, x_max, y_max] - dict should be in pascal_voc format using the keys {“x_min”: 0, “y_min”: 0, “x_max”: 1, “y_max”: 1, “label”: ‘none’} If passing an ndarray, it should be of shape (N,4).\n:param label: a list of strs that has the class name or label for the object in the corresponding box.\nGenerate random coordinates:\n\nnp.random.seed(42)\nannots = [sorted([np.random.randint(100) for i in range(4)]) for j in range(3)]\nannots\n\n[[14, 51, 71, 92], [20, 60, 82, 86], [74, 74, 87, 99]]\n\n\nAll annotations are stored as a BaseBx in a container called MultiBx\n\nbxs = MultiBx(annots, ['apple', 'coke', 'tree'])\nbxs\n\nMultiBx(coords=[[14, 51, 71, 92], [20, 60, 82, 86], [74, 74, 87, 99]], label=['apple', 'coke', 'tree'])\n\n\nEach index reveals the stored coordinate as a BaseBx\n\nbxs[0]\n\nBaseBx(coords=[[14, 51, 71, 92]], label=['apple'])\n\n\nThey can also be iterated:\n\nnext(bxs)\n\nBaseBx(coords=[[14, 51, 71, 92]], label=['apple'])\n\n\nOr using list comprehension, properties of individual boxes can be extracted\n\n[b.area for b in bxs]\n\n[1612, 325]\n\n\n\nbxs[0].valid\n\nTrue\n\n\n\nbxs[1].yolo()\n\n(#1) [[51.0, 73.0, 62.0, 26.0]]\n\n\n\nbxs[0].area\n\n2337\n\n\n\n[b_.area for b_ in bxs]\n\n[2337, 1612, 325]\n\n\nExtending BaseBx to also accept (json, dict) formatted coordinates and labels.\n\nsource\n\n\njbx\n\n jbx (coords=None, labels=None, keys=None)\n\nAlias of the JsonBx class to process json records into MultiBx or BaseBx objects exposing many validation methods\nAlso accepts keys as a list, otherwise uses voc_keys.\n\nannots = json.load(open('../data/annots.json'))\nannots\n\n[{'x_min': 130, 'y_min': 63, 'x_max': 225, 'y_max': 180, 'label': 'clock'},\n {'x_min': 13, 'y_min': 158, 'x_max': 90, 'y_max': 213, 'label': 'frame'}]\n\n\n\njbx(annots, keys=voc_keys)\n\n__JsonBx(coords=[[130, 63, 225, 180], [13, 158, 90, 213]], label=['clock', 'frame'])\n\n\nAlso accepts keys (for the dict) as a list, otherwise uses voc_keys.\n\nvoc_keys\n\n['x_min', 'y_min', 'x_max', 'y_max', 'label']\n\n\nMaking MultiBx work with lists with more than 4 items. It is a common practice to have the class label along with the coordinates. This classmethod is useful in such situations\n\nITER_TYPES\n\n(numpy.ndarray, list, fastcore.foundation.L)\n\n\n\nsource\n\n\nlbx\n\n lbx (coords=None, labels=None)\n\nAlias of the __ListBx class to process list into MultiBx or BaseBx objects exposing many validation methods\n\nannots = [[10, 20, 100, 200, 'apple'], [40, 50, 80, 90, 'coke'], ]\nannots\n\n[[10, 20, 100, 200, 'apple'], [40, 50, 80, 90, 'coke']]\n\n\n\nlbx(annots)\n\n__ListBx(coords=[[10, 20, 100, 200], [40, 50, 80, 90]], label=['apple', 'coke'])\n\n\n\nlbx(annots)[0]\n\nBaseBx(coords=[[10, 20, 100, 200]], label=['apple'])\n\n\nInserting classmethod to process lists and dicts in MultiBx.\n\nsource\n\n\nmbx\n\n mbx (coords=None, label=None, keys=None)\n\nAlias of the MultiBx class.\n\nsource\n\n\nMultiBx.multibox\n\n MultiBx.multibox (coords, label:list=None, keys:list=None)\n\nClassmethod for MultiBx. Same as mbx(coords, label). Calls classmethods of JsonBx and ListBx based on the type of coords passed.\n\nannots_list = annots\nannots_list\n\n[[10, 20, 100, 200, 'apple'], [40, 50, 80, 90, 'coke']]\n\n\n\nannots_json = json.load(open('../data/annots.json'))\nannots_json\n\n[{'x_min': 130, 'y_min': 63, 'x_max': 225, 'y_max': 180, 'label': 'clock'},\n {'x_min': 13, 'y_min': 158, 'x_max': 90, 'y_max': 213, 'label': 'frame'}]\n\n\nHow the class method works:\n\nt = explode_types(annots_list)  # get all types\nt\n\n{list: [{list: [int, int, int, int, str]}, {list: [int, int, int, int, str]}]}\n\n\n\nt[list][0]  # index into the nested list and call the right class\n\n{list: [int, int, int, int, str]}\n\n\n\nmbx(annots_json)\n\nMultiBx(coords=[[130, 63, 225, 180], [13, 158, 90, 213]], label=['clock', 'frame'])\n\n\n\nmbx(annots_list)\n\nMultiBx(coords=[[10, 20, 100, 200], [40, 50, 80, 90]], label=['apple', 'coke'])\n\n\n\nmbx(annots_json[0])\n\nMultiBx(coords=[[130, 63, 225, 180]], label=['clock'])\n\n\nChecking if it works with ndarrays\n\nnp.random.seed(42)\nannots = np.array([sorted([np.random.randint(100) for i in range(4)]) for j in range(3)])\nannots\n\narray([[14, 51, 71, 92],\n       [20, 60, 82, 86],\n       [74, 74, 87, 99]])\n\n\n\nmbx(annots)\n\nMultiBx(coords=[[14, 51, 71, 92], [20, 60, 82, 86], [74, 74, 87, 99]], label=[None, None, None])\n\n\nAllowing BaseBx to process a single dict and list directly.\n\nsource\n\n\nbbx\n\n bbx (coords=None, labels=None, keys=['x_min', 'y_min', 'x_max', 'y_max',\n      'label'])\n\nAlias of the BaseBx class.\n\nsource\n\n\nBaseBx.basebx\n\n BaseBx.basebx (coords, label:list=None, keys:list=['x_min', 'y_min',\n                'x_max', 'y_max', 'label'])\n\nClassmethod for BaseBx. Same as bbx(coords, label), made to work with other object types other than ndarray.\nRemember that BaseBx can only have one box coordinate and label at a time.\n\nannots_list\n\n[[10, 20, 100, 200, 'apple'], [40, 50, 80, 90, 'coke']]\n\n\nWhat does make_single_iterable do? It converts a single list or dict of coordinates into an iterable list that can be used by BaseBx.\n\nannots_list[0]\n\n[10, 20, 100, 200, 'apple']\n\n\n\nmake_single_iterable(annots_list[0], keys=voc_keys)\n\n((#1) [[10, 20, 100, 200]], ['apple'])\n\n\nThe class method makes it easier to directly call BaseBx without making the coordinates a list of list.\n\nbbx(annots_list[0])\n\nBaseBx(coords=[[10, 20, 100, 200]], label=['apple'])\n\n\n\nannots_list[0][:-1]\n\n[10, 20, 100, 200]\n\n\n\nbbx(annots_list[0][:-1])  # if label is not passed\n\nBaseBx(coords=[[10, 20, 100, 200]], label=[])\n\n\n\nbbx(annots_json[0])\n\nBaseBx(coords=[[130, 63, 225, 180]], label=['clock'])\n\n\n\n\nget_bx\nWhen in doubt, use get_bx.\n\nITER_TYPES\n\n(numpy.ndarray, list, fastcore.foundation.L)\n\n\n/mnt/data/projects/pybx/.venv/lib/python3.7/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section Raises\n  else: warn(msg)\n\nsource\n\nget_bx\n\n get_bx (coords, label=None)\n\nHelper function to check and call the correct type of Bx instance.\nChecks for the type of data passed and calls the respective class to generate a Bx instance. Currently only supports ndarray, list, dict, tuple, nested list, nested tuple.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncoords\nndarray, list, dict, tuple, nested list, nested tuple\n\nCoordinates of anchor boxes.\n\n\nlabel\nNoneType\nNone\nLabels for anchor boxes in order, by default None\n\n\nReturns\nBx\n\nAn instance of MultiBx, ListBx, BaseBx or JsonBx\n\n\n\nget_bx runs a bunch of if-else statements to call the right module when in doubt.\n\nannots_json\n\n[{'x_min': 130, 'y_min': 63, 'x_max': 225, 'y_max': 180, 'label': 'clock'},\n {'x_min': 13, 'y_min': 158, 'x_max': 90, 'y_max': 213, 'label': 'frame'}]\n\n\n\nget_bx(annots_json)\n\nMultiBx(coords=[[130, 63, 225, 180], [13, 158, 90, 213]], label=['clock', 'frame'])\n\n\n\nlen(annots_json[0])\n\n5\n\n\n\nget_bx([annots_json[0]])\n\nMultiBx(coords=[[130, 63, 225, 180]], label=['clock'])\n\n\n\nget_bx(annots_list)\n\nMultiBx(coords=[[10, 20, 100, 200], [40, 50, 80, 90]], label=['apple', 'coke'])\n\n\n\nget_bx([0, 1, 0, 1])\n\nBaseBx(coords=[[0, 1, 0, 1]], label=[])\n\n\nThe addition operation stacks the bounding boxes.\n\nsource\n\n\nadd_bxs\n\n add_bxs (b1, b2)\n\nAlias of stack_bxs().\n\nsource\n\n\nstack_bxs\n\n stack_bxs (b1, b2)\n\nMethod to stack two Bx-types together. Similar to __add__ of BxTypes but avoids UserWarning. :param b1: :param b2: :return:\nsummary\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nb1\nBx, MultiBx\nAnchor box coordinates Bx\n\n\nb2\nBx, MultiBx\nAnchor box coordinates Bx\n\n\nReturns\nMultiBx\nStacked anchor box coordinates of MultiBx type.\n\n\n\n\nb\n\nBaseBx(coords=[[14, 51, 71, 92]], label=['flower'])\n\n\nInternally this is what is done to stack them:\n\nbxs.coords + b.coords, bxs.label + b.label\n\n([[14, 51, 71, 92], [20, 60, 82, 86], [74, 74, 87, 99], [14, 51, 71, 92]],\n (#4) ['apple','coke','tree','flower'])\n\n\n\nbxs + b\n\nMultiBx(coords=[[14, 51, 71, 92], [20, 60, 82, 86], [74, 74, 87, 99], [14, 51, 71, 92]], label=['apple', 'coke', 'tree', 'flower'])\n\n\nAdding a MultiBx to a BaseBx makes the new set of coordinates a MultiBx, so a BxViolation warning is issued if this was not intended.\n\nb + bxs\n\n/mnt/data/projects/pybx/.venv/lib/python3.7/site-packages/ipykernel_launcher.py:19: BxViolation: Change of object type imminent if trying to add <class '__main__.BaseBx'>+<class '__main__.MultiBx'>. Use <class '__main__.MultiBx'>+<class '__main__.BaseBx'> instead or basics.stack_bxs().\n\n\nMultiBx(coords=[[14, 51, 71, 92], [14, 51, 71, 92], [20, 60, 82, 86], [74, 74, 87, 99]], label=['flower', 'apple', 'coke', 'tree'])\n\n\n\nstack_bxs(b, bxs)\n\nMultiBx(coords=[[14, 51, 71, 92], [14, 51, 71, 92], [20, 60, 82, 86], [74, 74, 87, 99]], label=['flower', 'apple', 'coke', 'tree'])\n\n\nTo avoid the BxViolation, use the method stack_bxs.\n\nstack_bxs(bxs, b)\n\nMultiBx(coords=[[14, 51, 71, 92], [20, 60, 82, 86], [74, 74, 87, 99], [14, 51, 71, 92]], label=['apple', 'coke', 'tree', 'flower'])\n\n\n\nsource\n\n\nstack_bxs_inplace\n\n stack_bxs_inplace (b, *args)\n\nStack the passed boxes on top of the first item.\n\nboxes = [BaseBx(coords=[[200, 100, 300, 200]], label=['a_3x3_1.0_5']),\n         BaseBx(coords=[[214, 79, 285, 220]], label=['a_3x3_0.5_5']),\n         BaseBx(coords=[[222, 58, 277, 241]], label=['a_3x3_0.3_5'])]\n\n\nstacked_bxs = stack_bxs_inplace(*boxes)\n\n\nstacked_bxs\n\nMultiBx(coords=[[200, 100, 300, 200], [214, 79, 285, 220], [222, 58, 277, 241]], label=['a_3x3_1.0_5', 'a_3x3_0.5_5', 'a_3x3_0.3_5'])\n\n\n\nlen(stacked_bxs)\n\n3\n\n\nBaseBx also supports calculation of bounding box offset by calling the get_offset() method.\n\nb1 = b\nb2 = BaseBx([[18, 44, 71, 90]], 'probably_flower')  # simulating the case where we might have a bbox prediction\nb1, b2\n\n(BaseBx(coords=[[14, 51, 71, 92]], label=['flower']),\n BaseBx(coords=[[18, 44, 71, 90]], label=['probably_flower']))\n\n\n\n(b.coords_as_numpy - b2.coords_as_numpy)\n\narray([[-4,  7,  0,  2]])\n\n\n\n(b.coords_as_numpy - b2.coords_as_numpy)/np.tile([2, 1], 2)\n\narray([[-2.,  7.,  0.,  2.]])\n\n\n\nsource\n\n\nBaseBx.get_offset\n\n BaseBx.get_offset (other:__main__.BaseBx, normalize=True, log_func=<ufunc\n                    'log'>, sigma=(0.1, 0.2), self_is_anchor=False)\n\nCaclulates the offset of the box I with another box O. The most basic calculation of offset involves a) taking the distance between the centers: I_cx - O_cx, I_cy - O_cy. b) taking the ratio of the two boxes: I_w/Ow, I_h/O_h.\nIf normalize=True, the center distances and ratios are normalized as per https://arxiv.org/pdf/1512.02325.pdf (I_cx - O_cx)/O_w, (I_cy - O_cy)/O_h, log(I_w/Ow), log(I_h/O_h) These are further scaled with an appoximation of standard deviation for the distances and ratios ((I_cx - O_cx)/O_w)/sigma_c, ((I_cy - O_cy)/O_h)/sigma_c, log(I_w/Ow)/sigma_r, log(I_h/O_h)/sigma_r\nArgs: other (BaseBx): Any supported type of bounding box format, even takes a list of coordinates. Typically the anchor box. normalize (bool, optional): Whether to normalize the offsets. Defaults to True. log_func (func, optional): Function for normalizing the ratio of widths and heights. Defaults to np.log. sigma (tuple, optional): Estimated of standard deviation for the distances and ratios. Defaults to (0.1, 0.2). self_is_anchor (bool, optional): Typically other is assumed to be the anchor box, this flag tells that this assumption is False. Defaults to False.\nReturns: list: Offsets of the two bounding boxes\n\nnp.repeat([1, 2], 2)\n\narray([1, 1, 2, 2])\n\n\n\nisinstance(b, BaseBx)\n\nTrue\n\n\n\nb, b2\n\n(BaseBx(coords=[[14, 51, 71, 92]], label=['flower']),\n BaseBx(coords=[[18, 44, 71, 90]], label=['probably_flower']))\n\n\n\nb.get_offset(b2, normalize=False)\n\n(#4) [-2.0,4.5,57.0,41.0]\n\n\n\nb.get_offset(b2, normalize=True)\n\n(#4) [-0.3774,0.9783,0.3638,-0.5753]\n\n\nTo make sure consistency with the reverse case where self is the ground truth anchor box and ground truth bounding box is the other box, use the self_is_anchor flag.\n\nb2.get_offset(b, normalize=True, self_is_anchor=True) # correct\n\n(#4) [-0.3774,0.9783,0.3638,-0.5753]\n\n\nIf self_is_anchor=False flag is not turned on, when ground truth bounding box is the other box, the latter can lead to a systematic bug.\n\nb2.get_offset(b, normalize=True)  # not correct\n\n(#4) [0.3509,-1.0976,-0.3638,0.5753]"
  },
  {
    "objectID": "utils.html",
    "href": "utils.html",
    "title": "Utilities",
    "section": "",
    "text": "np.random.seed(42)\n\n\nsource\n\nvalidate_boxes\n\n validate_boxes (coords, image_sz, feature_sz, clip=True,\n                 min_visibility=0.25)\n\nValidate calculated anchor box coords. :param coords: anchor box coordinates :param image_sz: tuple of (width, height) of an image :param feature_sz: tuple of (width, height) of a channel :param clip: whether to apply np.clip :param min_visibility: minimum visibility dictates the condition for a box to be considered valid. The value corresponds to the ratio of expected area to the calculated area after clipping to image dimensions. :return: anchor box coordinates in [pascal_voc] format\n\nsource\n\n\nget_edges\n\n get_edges (image_sz:tuple, feature_sz:tuple, op='noop')\n\nGenerate offsetted top (x_min, y_min) or bottom edges (x_max, y_max) coordinates of a given feature size based on op. if op is noop, gets the top edges. if op is add, gets the bottom edges. :param op: operation for calculating edges, either ‘add’ ‘sub’ ‘noop’ :param image_sz: tuple of (W, H) of an image :param feature_sz: tuple of (W, H) of a channel :return: offsetted edges of each feature\nGenerate (x_min, y_min) corners.\n\nsource\n\n\nas_tuple\n\n as_tuple (x)\n\nGet x as a tuple (x, x) if not already a tuple.\n\n\n\n\nType\nDetails\n\n\n\n\nx\n(int, tuple)\nItem that needs to be converted to a tuple.\n\n\n\n\nas_tuple(2)\n\n(2, 2)\n\n\n\nsource\n\n\nreassign_label\n\n reassign_label (gt_bx:pybx.basics.BaseBx, label=None)\n\nUpdate the label of the bounding box.\nArgs: gt_bx (BaseBx): A pybx bounding box of type BaseBx. label (list, optional): New label as a list of single item. Defaults to None.\nReturns: type: description"
  },
  {
    "objectID": "ops.html",
    "href": "ops.html",
    "title": "Operations",
    "section": "",
    "text": "source\n\nupdate_keys\n\n update_keys (annots:dict, default_keys=None)\n\nModify the default class label key that the JsonBx method looks for. By default, JsonBx uses the parameter ops.voc_keys and looks for the key “label” in the dict. If called, update_keys looks inside the parameter ops.label_keys for matching key in the passed annots and uses this as the key to identify class label. Fixes #3. :param annots: dictionary of annotations :param default_keys: voc_keys by default :return: new keys with updated label key\n\nsource\n\n\nintersection_box\n\n intersection_box (b1:list, b2:list)\n\nReturn the box that intersects two boxes in pascal_voc format.\n\nsource\n\n\nnamed_idx\n\n named_idx (ncoords:int, sfx:str='')\n\nReturn a list of indices as str matching the array size, suffixed with sfx :param ncoords: number of coordinates :param sfx: suffix to be added to the index :return: list of strings\n\nsource\n\n\nmake_single_iterable\n\n make_single_iterable (x, keys=['x_min', 'y_min', 'x_max', 'y_max',\n                       'label'])\n\nMethod to convert a single dict or a list to an array. :param x: dict with keys {“x_min”: 0, “y_min”: 0, “x_max”: 1, “y_max”: 1, “label”: ‘none’} :return: coords as ndarray, label as list\n\nsource\n\n\nget_op\n\n get_op (op:str)\n\nGiven a string of aps.__ops__, return the function reference.\n\nsource\n\n\nnoop\n\n noop (x, _)\n\nPerform no operation (“no-op”) on x. :param x: input object 1 :param _: input object 2 :return: input object 1\n\nsource\n\n\nmul\n\n mul (x, y)\n\nMultiply two objects.\n\nsource\n\n\nsub\n\n sub (x, y)\n\nSubtract two objects.\n\nsource\n\n\nadd\n\n add (x, y)\n\nAdd two objects."
  },
  {
    "objectID": "sample.html",
    "href": "sample.html",
    "title": "Samples",
    "section": "",
    "text": "np.random.seed(1)\n\n\nannot = json.load(open('../data/annots.json'))\nannot\n\n[{'x_min': 130, 'y_min': 63, 'x_max': 225, 'y_max': 180, 'label': 'clock'},\n {'x_min': 13, 'y_min': 158, 'x_max': 90, 'y_max': 213, 'label': 'frame'}]\n\n\nRescale the annotations to match the new image size. Can individually process dicts.\n\norig_sz=(256, 256)\nnew_sz=(200, 200)\n\n\n_scale_annots_dict(annot[0], new_sz=new_sz, orig_sz=orig_sz)\n\n{'x_min': 102, 'y_min': 49, 'x_max': 176, 'y_max': 141, 'label': 'clock'}\n\n\nProcesses lists of dicts\n\n_get_scaled_annots(annot, new_sz, orig_sz)\n\n[{'x_min': 102, 'y_min': 49, 'x_max': 176, 'y_max': 141, 'label': 'clock'},\n {'x_min': 10, 'y_min': 123, 'x_max': 70, 'y_max': 166, 'label': 'frame'}]\n\n\nAlso works with lists with labels.\n\n_get_scaled_annots([[100, 150, 180, 256, 'hat'], [100, 120, 256, 200, 'shirt']], new_sz, orig_sz)\n\n[{'x_min': 78, 'y_min': 117, 'x_max': 141, 'y_max': 200, 'label': 'hat'},\n {'x_min': 78, 'y_min': 94, 'x_max': 200, 'y_max': 156, 'label': 'shirt'}]\n\n\n\n_get_scaled_annots([[100, 150, 180, 256], [100, 120, 256, 200]], new_sz, orig_sz) # without labels\n\n[{'x_min': 78, 'y_min': 117, 'x_max': 141, 'y_max': 200},\n {'x_min': 78, 'y_min': 94, 'x_max': 200, 'y_max': 156}]\n\n\n\ncv2.cvtColor(cv2.imread('../data/image.jpg'), cv2.COLOR_BGR2RGB).shape\n\n(256, 256, 3)\n\n\n\nimg, annots, logits, color = _get_example(\n    image_sz=orig_sz,\n    feature_sz=(10, 10),\n    pth=\"../data\",\n    img_fn=\"image.jpg\",\n    load_ann=True,\n    ann_fn=\"annots.json\",\n)\n\n\nannots # will not change as the same size is kept\n\n[{'x_min': 130, 'y_min': 63, 'x_max': 225, 'y_max': 180, 'label': 'clock'},\n {'x_min': 13, 'y_min': 158, 'x_max': 90, 'y_max': 213, 'label': 'frame'}]\n\n\n\njson.load(open('../data/annots.json'))\n\n[{'x_min': 130, 'y_min': 63, 'x_max': 225, 'y_max': 180, 'label': 'clock'},\n {'x_min': 13, 'y_min': 158, 'x_max': 90, 'y_max': 213, 'label': 'frame'}]\n\n\n\nimg, annots, logits, color = _get_example(\n    image_sz=new_sz, # change image size\n    feature_sz=(10, 10),\n    pth=\"../data\",\n    img_fn=\"image.jpg\",\n    load_ann=True,\n    ann_fn=\"annots.json\",\n)\n\n\nannots\n\n[{'x_min': 102, 'y_min': 49, 'x_max': 176, 'y_max': 141, 'label': 'clock'},\n {'x_min': 10, 'y_min': 123, 'x_max': 70, 'y_max': 166, 'label': 'frame'}]\n\n\n\nsource\n\nget_given_array\n\n get_given_array (image_arr, **kwargs)\n\nGet the image_array setup for visualisation. :param image_arr: image nparray :return: reference to protected _get_given_array()\n\nsource\n\n\nget_example\n\n get_example (image_sz:tuple, **kwargs)\n\nGet an example image from the pth given for some image size for a feature size :param image_sz: required image size (will resize the original image) :return: reference to protected _get_example()"
  },
  {
    "objectID": "vis.html",
    "href": "vis.html",
    "title": "Visualizations",
    "section": "",
    "text": "Loading from disk\nLoad a sample image from the data directory ../data/image.jpg and resize to (200, 200). Original image size is (256, 256).\n\nimage_sz=(200, 200)\n\nim, ann, lgt, clr = get_example(image_sz=image_sz, pth=\"../data\", img_fn=\"image.jpg\")\n\nim is the image of a clock and a frame, ann are the annotations for the image in json format, lgt are logits (activations from a layer) which can be displayed on top of the image, clr is a dict representing the colors to use for the different annotation keys.\n\nann, lgt, clr\n\n([{'x_min': 102, 'y_min': 49, 'x_max': 176, 'y_max': 141, 'label': 'clock'},\n  {'x_min': 10, 'y_min': 123, 'x_max': 70, 'y_max': 166, 'label': 'frame'}],\n None,\n {'frame': 'blue', 'clock': 'green'})\n\n\n\n_ = plt.imshow(im)\n\n\n\n\nStore the annotations as a MultiBx object.\n\nget_bx(ann)\n\nMultiBx(coords=[[102, 49, 176, 141], [10, 123, 70, 166]], label=['clock', 'frame'])\n\n\n\nsource\n\n\ndraw\n\n draw (img:numpy.ndarray, bbox:list, logits=None, alpha=0.4, **kwargs)\n\nMethod to draw an image, box and logits overlayed if passed. :param img: the image array, expects a numpy array :param bbox: list of bounding boxes in json format :param logits: activations that should be overlayed from a neural network (no checks) :param kwargs: kwargs for draw_boxes() :param alpha: same as alpha for matplotlib :return: current axis\n\nsource\n\n\ndraw_boxes\n\n draw_boxes (img:numpy.ndarray, bbox:list, title=None, ax=None,\n             figsize=(5, 4), color='yellow', no_ticks=False, xo=0, yo=0,\n             squeeze=False, **kwargs)\n\nMethod to draw bounding boxes in an image, can handle multiple bboxes :param figsize: sige of figure :param img: the image array, expects a numpy array :param bbox: list of bounding boxes in json format :param title: image title :param ax: which axis if already present :param yo: y offset for placement of text :param xo: x offset for placement of text :param color: text color or dict of colors for each label as a dict :param no_ticks: whether to set axis ticks off :param squeeze: squeeze axis :return: ax with image\n\nsource\n\n\ndraw_rectangle\n\n draw_rectangle (ax, coords, color='white')\n\nDraw a rectangle using matplotlib patch. :param ax: axis :param coords: coordinates in coco format :param color: text color :return: ax object\n\nsource\n\n\ndraw_text\n\n draw_text (ax, xy:tuple, label:str, size=12, color='white', xo=0, yo=0)\n\nWrite text around boxes. :param ax: axis object :param xy: relative ax coordinates x, y to draw the text :param label: label for box :param size: font size :param yo: y offset for placement of text :param xo: x offset for placement of text :param color: text color :return: ax object\n\nsource\n\n\nget_extents\n\n get_extents (shape)\n\nGet extent parameter of the image.\n\nsource\n\n\nget_color\n\n get_color (color, label=None, default_color='white')\n\nGet colors from color dict for a given label. If label=None, return default_color. :param color: dict of key, value pairs where key is label, value is color :param label: the label for which color is needed :param default_color: :return: str that contains color\n\nsource\n\n\ndraw_outline\n\n draw_outline (obj, linewidth:int)\n\nMake outlines around to object edges for visibility in light backgrounds :param obj: plt objects like text or rectangle :param linewidth: width of the stroke :return: plt object\nDrawing random box by passing coordinates as a list.\n\ndraw(im, [[20, 20, 80, 80]])\n\n<AxesSubplot:>\n\n\n\n\n\nDrawing random box by passing coordinates as a list along with label.\n\ndraw(im, [[20, 20, 80, 80, 'random']], color={'random': 'blue'})\n\n<AxesSubplot:>\n\n\n\n\n\n\ndraw(im, [{'x_min': 50, 'y_min': 30, 'x_max':100, 'y_max':120, 'label':'random'}], \\\n    color={'random': 'green'})\n\n<AxesSubplot:>\n\n\n\n\n\nTo display the calculated anchor boxes or any other type of bounding boxes, pybx offers the vis.VisBx class. First, vis.VisBx initializes all the params for the image and loads its annotations (if available). Upon calling the show() method on the instantiated VisBx object with our predicted annotations or anchor boxes, everything gets displayed.\n\nsource\n\n\nVisBx\n\n VisBx (image_arr=None, image_sz=None, sample=False, **kwargs)\n\nVisBx is used to visualize the bounding boxes. The image on of which the bounding boxes are to be drawn can be instantiated with VisBx() if needed. Calling the show() method of the VisBx() instance accepts bounding box coordinates and labels that are to be shown. The boxes can be provided as any of the internal objects (MultiBx, BaseBx, …) or as any other raw format accepted by the internal objects.\nDisplaying image array and annotations object: This is the default approach used by VisBx(). If no arguments are passed, a tuple denoting the size for random noise random_img_sz=(100, 100, 1) is expected. Some arguments: :param image_arr: image array of shape (H, W, C). If None, it is set to a random noise image of image_sz=(100,100,3) by default. :param annots: annotations is any accepted format (see above).\nDisplaying from image and annotations file: To load and display the image, set sample=True. Some argmuments: :param ann_fn: annotations file name, default annots.json :param img_fn: image file name, default image.jpg :param load_ann: whether to load ann_fn or just the img_fn. If False, an empty annotations dict is returned: dict(zip(voc_keys, [0, 0, 1, 1, ''])) :param pth: path to find ann_fn and img_fn, default . :param image_sz: size to resize the loaded image a different size (annotations scaled automatically)\nCommon parameters: :param color: A dict of color can be passed to assign specific color to a specific label in the image: color = {'frame': 'blue', 'clock': 'green'} :param logits: Logits as ndarray that should be overlayed on top of the image or bool to generate random logits. :param feature_sz: Feature size to generate random logits if logits is not None.\n\n\nDisplay image array (default behaviour)\nTo display an image array (shape of W, H, C) directly, instead of loading from disk, pass an ndarray to the image_arr argument. If available, also provide the annots in any supported format. Displaying calculated anchors with a random image:\n\nanchor_boxes, anchor_labels = bx(image_sz, 3, 1)\n\n\nv = VisBx(image_arr=np.random.random((*image_sz, 3)))  # a 200x200 image is used to overlay the anchor boxes in a 3x3 grid\nv.show(anchor_boxes, anchor_labels)\n\n<AxesSubplot:>\n\n\n\n\n\n\nv = VisBx(image_arr=np.random.random((10, 10, 3)), image_sz=(*image_sz, 3))  # a 10x10 random image will be resized to 200x200\nv.show(anchor_boxes, anchor_labels)\n\n<AxesSubplot:>\n\n\n\n\n\n\n\nLoad image and show annots\nDisplaying calculated anchors with a sample image. The original annotations are also rescaled to match the image_sz.\n\nv = VisBx(pth='../data/', img_fn='image.jpg', image_sz=image_sz)  # annots.json is being read from ../data/annots.json\nv.show(anchor_boxes, anchor_labels)\n\n<AxesSubplot:>\n\n\n\n\n\n\n\nCustomize colors\nTo customize the box colors, pass a dict color with the annotation name as key and color as value. In the example below an anchor box color is changed to red using its label a_3x3_1.0_3 along with the annotations provided read from file.\n\nv.show(anchor_boxes, anchor_labels, color={'a_3x3_1.0_3': 'red', 'frame': 'green', 'clock': 'green'})\n\n<AxesSubplot:>"
  },
  {
    "objectID": "excepts.html",
    "href": "excepts.html",
    "title": "Exceptions",
    "section": "",
    "text": "source\n\nNoGroundTruthBxs\nNo Ground Truth boxes found.\n\nsource\n\n\nBxViolation\nViolation of Bx properties.\n\nsource\n\n\nNoIntersection\nNo intersection of boxes occur."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PyBx",
    "section": "",
    "text": "Installation\npip install pybx\n\n\nUsage\nTo calculate the anchor boxes for a single feature size and aspect ratio, given the image size:\n\nfrom pybx import anchor, ops\n\nimage_sz = (256, 256)\nfeature_sz = (10, 10)\nasp_ratio = 1/2.\n\ncoords, labels = anchor.bx(image_sz, feature_sz, asp_ratio)\n\n100 anchor boxes of asp_ratio 0.5 is generated along with unique labels:\n\nlen(coords), len(labels)\n\n(100, 100)\n\n\nThe anchor box labels are especially useful, since they are pretty descriptive:\n\ncoords[-1], labels[-1]\n\n([234, 225, 252, 256], 'a_10x10_0.5_99')\n\n\nTo calculate anchor boxes for multiple feature sizes and aspect ratios, we use anchor.bxs instead:\n\nfeature_szs = [(10, 10), (8, 8)]\nasp_ratios = [1., 1/2., 2.]\n\ncoords, labels = anchor.bxs(image_sz, feature_szs, asp_ratios)\n\nAll anchor boxes are returned as ndarrays of shape (N,4) where N is the number of boxes.\nThe box labels are even more important now, since they help you uniquely identify to which feature map size or aspect ratios they belong to.\n\ncoords[101], labels[101]\n\n(array([29,  0, 47, 30]), 'a_10x10_0.5_1')\n\n\n\ncoords[-1], labels[-1]\n\n(array([217, 228, 256, 251]), 'a_8x8_2.0_63')\n\n\n\nMultiBx methods\nBox coordinates (with/without labels) in any format (usually ndarray, list, json, dict) can be instantialized as a MultiBx, exposing many useful methods and attributes of MultiBx. For example to calculate the area of each box iteratively:\n\nfrom pybx.basics import * \n# passing anchor boxes and labels from anchor.bxs()\nprint(coords.shape)\n\nboxes = mbx(coords, labels)\ntype(boxes)\n\n(492, 4)\n\n\npybx.basics.MultiBx\n\n\n\nlen(boxes)\n\n492\n\n\n\nareas = [b.area for b in boxes]\n\nEach annotation in the MultiBx object boxes is also a BaseBx with its own set of methods and properties.\n\nboxes[-1]\n\nBaseBx(coords=[[217, 228, 256, 251]], label=['a_8x8_2.0_63'])\n\n\n\nboxes[-1].coords, boxes[-1].label\n\n([[217, 228, 256, 251]], (#1) ['a_8x8_2.0_63'])\n\n\nMultiBx objects can also be “added” which stacks them vertically to create a new MultiBx object:\n\nboxes_true = mbx(coords_json)    # annotation as json records\nlen(boxes_true)\n\n2\n\n\n\nboxes_anchor = mbx(coords_numpy) # annotation as ndarray\nlen(boxes_anchor)\n\n492\n\n\n\nboxes_true\n\nMultiBx(coords=[[130, 63, 225, 180], [13, 158, 90, 213]], label=['clock', 'frame'])\n\n\n\nboxes = boxes_true + boxes_anchor + boxes_true\n\n\nlen(boxes)\n\n496\n\n\n\n\n\nUse ground truth boxes for model training\n\nfrom pybx.anchor import get_gt_thresh_iou, get_gt_max_iou\nfrom pybx.vis import VisBx\n\n\nimage_sz\n\n(256, 256)\n\n\n\nboxes_true\n\nMultiBx(coords=[[130, 63, 225, 180], [13, 158, 90, 213]], label=['clock', 'frame'])\n\n\nCalculate candidate anchor boxes for many aspect ratios and scales.\n\nfeature_szs = [(10, 10), (3, 3), (2, 2)]\nasp_ratios = [0.3, 1/2., 2.]\n\nanchors, labels = anchor.bxs(image_sz, feature_szs, asp_ratios)\n\nWrap using pybx methods. This step is not necessary but convenient.\n\nboxes_anchor = get_bx(anchors, labels) \nlen(boxes_anchor)\n\n341\n\n\nThe following function returns two positive ground truth anchors with largest IOU for each class in the label bounding boxes passed.\n\ngt_anchors, gt_ious, gt_masks = get_gt_max_iou( \n    true_annots=boxes_true, \n    anchor_boxes=boxes_anchor,  # if plain numpy, pass anchor_boxes and anchor_labels \n    update_labels=False,  # whether to replace ground truth labels with true labels\n    positive_boxes=1,  # can request extra boxes \n)\n\n\ngt_anchors\n\n{'clock': BaseBx(coords=[[156, 0, 227, 180]], label=['a_2x2_0.3_1']),\n 'frame': BaseBx(coords=[[12, 152, 72, 256]], label=['a_3x3_0.5_6'])}\n\n\n\nall_gt_anchors = gt_anchors['clock'] + gt_anchors['frame']\nall_gt_anchors\n\n/mnt/data/projects/pybx/pybx/basics.py:464: BxViolation: Change of object type imminent if trying to add <class 'pybx.basics.BaseBx'>+<class 'pybx.basics.BaseBx'>. Use <class 'pybx.basics.BaseBx'>+<class 'pybx.basics.BaseBx'> instead or basics.stack_bxs().\n  f\"Change of object type imminent if trying to add \"\n\n\nMultiBx(coords=[[156, 0, 227, 180], [12, 152, 72, 256]], label=['a_2x2_0.3_1', 'a_3x3_0.5_6'])\n\n\n\nv = VisBx(pth='../data/', img_fn='image.jpg', image_sz=image_sz)\nv.show(all_gt_anchors, color={'a_2x2_0.3_1':'red', 'a_3x3_0.5_6': 'red'})\n\n<AxesSubplot:>\n\n\n\n\n\nMore exploratory stuff in the walkthrough notebook!"
  }
]