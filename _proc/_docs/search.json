[
  {
    "objectID": "anchor.html",
    "href": "anchor.html",
    "title": "Generate anchor boxes",
    "section": "",
    "text": "To generate anchor boxes, we need three basic information:\n\nInput image size, image_sz: To position our anchor boxes within the maximum coordinates (width, height) of the image.\nFeature map size, feature_sz: Feature map is the size (width, height) of the output of a convolutional operation. A \\(10\\times10\\) feature map would mean \\(10\\times10\\) local receptive field locations can be traced back into the input image. These 100 receptive field locations (\\(10\\times10=100\\)) in the input image would act as our initial anchor box candidates.\n\n\n\nAspect ratio of anchor boxes, asp_ratio: To generate anchor boxes with different width to height ratio (default asp_ratio=1).\n\n\nsource\n\nbx\n\n bx (image_sz:(<class'int'>,<class'tuple'>),\n     feature_sz:(<class'int'>,<class'tuple'>), asp_ratio:float=None,\n     clip:bool=True, named:bool=True, anchor_sfx:str='a',\n     min_visibility:float=0.25)\n\nCalculate anchor box coords given an image size and feature size for a single aspect ratio.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nimage_sz\n(<class ‘int’>, <class ‘tuple’>)\n\nimage size (width, height)\n\n\nfeature_sz\n(<class ‘int’>, <class ‘tuple’>)\n\nfeature map size (width, height)\n\n\nasp_ratio\nfloat\nNone\naspect ratio (width:height), by default None\n\n\nclip\nbool\nTrue\nwhether to apply np.clip, by default True\n\n\nnamed\nbool\nTrue\nwhether to return (coords, labels), by default True\n\n\nanchor_sfx\nstr\na\nsuffix anchor label with anchor_sfx, by default “a”\n\n\nmin_visibility\nfloat\n0.25\nminimum visibility dictates the condition for a box to be consideredvalid. The value corresponds to the ratio of expected area of an anchor boxto the calculated area after clipping to image dimensions., by default 0.25\n\n\nReturns\ntyping.Union[typing.Sequence[typing.Sequence[typing.Sequence[typing.Sequence[typing.Sequence[typing.Any]]]]], numpy.typing._array_like._SupportsArray[numpy.dtype], typing.Sequence[numpy.typing._array_like._SupportsArray[numpy.dtype]], typing.Sequence[typing.Sequence[numpy.typing._array_like._SupportsArray[numpy.dtype]]], typing.Sequence[typing.Sequence[typing.Sequence[numpy.typing._array_like._SupportsArray[numpy.dtype]]]], typing.Sequence[typing.Sequence[typing.Sequence[typing.Sequence[numpy.typing._array_like._SupportsArray[numpy.dtype]]]]], bool, int, float, complex, str, bytes, typing.Sequence[typing.Union[bool, int, float, complex, str, bytes]], typing.Sequence[typing.Sequence[typing.Union[bool, int, float, complex, str, bytes]]], typing.Sequence[typing.Sequence[typing.Sequence[typing.Union[bool, int, float, complex, str, bytes]]]], typing.Sequence[typing.Sequence[typing.Sequence[typing.Sequence[typing.Union[bool, int, float, complex, str, bytes]]]]]]\n\nanchor box coordinates in pascal_voc formatif named=True, a list of anchor box labels are also returned.\n\n\n\n\ncoords_1, labels_1 = bx(100, 10, 0.5)\n\nUsually multiple anchor boxes with different feature_sz and asp_ratio are needed. This requirement arises in the case of multiscale object detection.\nFor multiscale object detection, feature maps from different convolution operations of the network are used to trace back into the input image, to generate anchor boxes. The bxs method of pybx provides this possibility.\n\nsource\n\n\nbxs\n\n bxs (image_sz:(<class'int'>,<class'tuple'>), feature_szs:list=None,\n      asp_ratios:list=None, named:bool=True, **kwargs)\n\nCalculate anchor box coords given an image size and multiple feature sizes for mutiple aspect ratios.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nimage_sz\n(<class ‘int’>, <class ‘tuple’>)\n\nimage size (width, height)\n\n\nfeature_szs\nlist\nNone\nlist of feature map sizes, each feature map size being an int or tuple, by default [(8, 8), (2, 2)]\n\n\nasp_ratios\nlist\nNone\nlist of aspect ratios for anchor boxes, each aspect ratio being a float calculated by (width:height), by default [1 / 2.0, 1.0, 2.0]\n\n\nnamed\nbool\nTrue\nwhether to return (coords, labels), by default True\n\n\nkwargs\n\n\n\n\n\nReturns\ntyping.Union[typing.Sequence[typing.Sequence[typing.Sequence[typing.Sequence[typing.Sequence[typing.Any]]]]], numpy.typing._array_like._SupportsArray[numpy.dtype], typing.Sequence[numpy.typing._array_like._SupportsArray[numpy.dtype]], typing.Sequence[typing.Sequence[numpy.typing._array_like._SupportsArray[numpy.dtype]]], typing.Sequence[typing.Sequence[typing.Sequence[numpy.typing._array_like._SupportsArray[numpy.dtype]]]], typing.Sequence[typing.Sequence[typing.Sequence[typing.Sequence[numpy.typing._array_like._SupportsArray[numpy.dtype]]]]], bool, int, float, complex, str, bytes, typing.Sequence[typing.Union[bool, int, float, complex, str, bytes]], typing.Sequence[typing.Sequence[typing.Union[bool, int, float, complex, str, bytes]]], typing.Sequence[typing.Sequence[typing.Sequence[typing.Union[bool, int, float, complex, str, bytes]]]], typing.Sequence[typing.Sequence[typing.Sequence[typing.Sequence[typing.Union[bool, int, float, complex, str, bytes]]]]]]\n\nanchor box coordinates in pascal_voc formatif named=True, a list of anchor box labels are also returned.\n\n\n\n\ncoords, labels = bxs(100, [10, 8, 5, 2], [1, 0.5, 0.3])\n\n\ncoords.shape, len(labels)\n\n((579, 4), 579)\n\n\nAll methods work with asymetric image_sz (and or feature_szs as well):\n\ncoords, labels = bxs((100, 200), [10, 8, 5, 2], [1, 0.5, 0.3])\n\n\ncoords.shape, len(labels)\n\n((654, 4), 654)"
  },
  {
    "objectID": "basics.html",
    "href": "basics.html",
    "title": "Basic objects",
    "section": "",
    "text": "import json\nfrom fastcore.test import test_eq, test_fail, test_warns, ExceptionExpected\n\nAnchor box coordinates of type list/dict/json/array can be converted to a Bx instance. Once wrapped as a Bx instance, some interesting properties can be calculated from the coordinates.\n\nsource\n\nBx\n\n Bx (coords, label:list=None)\n\nInterface for all future Bx’s\nInitializing an empty Bx class. It does a whole lot of things!\nGenerate random coordinates for one anchor boxes.\n\nnp.random.seed(42)\nannots = [sorted([np.random.randint(100) for i in range(4)])]\nannots\n\n[[14, 51, 71, 92]]\n\n\nIf a single list is passed, Bx will make it a list of list.\n\nBx(annots[0])\n\nBx(coords=[[14, 51, 71, 92]], label=[])\n\n\nSo the correct way to do it would be to pass a list of list.\n\nannots\n\n[[14, 51, 71, 92]]\n\n\n\nb = Bx(annots)\nb\n\nBx(coords=[[14, 51, 71, 92]], label=[])\n\n\n\nlen(b)\n\n1\n\n\n\nb.cx\n\n42.5\n\n\n\nb.yolo()\n\n(#1) [[42.5, 71.5, 57, 41]]\n\n\nTo get normalized coordinates wrt to the image dimensions.\n\nb.yolo(224, 224, normalize=True)\n\n(#1) [[0.18973214285714285, 0.31919642857142855, 0.2544642857142857, 0.18303571428571427]]\n\n\n\nb.values\n\n(#1) [[14, 51, 71, 92]]\n\n\nBx is inherited by all other types in pybx: BaseBx, MultiBx, ListBx, JsonBx, exposing the same properties.\nBaseBx works with other types of coordinates too. It accepts the coordinates and label for one anchor box in a list or ndarray format.\n\nsource\n\n\nBaseBx\n\n BaseBx (coords, label:list=None)\n\nBaseBx is the most primitive form of representing a bounding box. Coordinates and label of a bounding box can be wrapped as a BaseBx using: bbx(coords, label).\n:param coords: can be of type list or array representing a single box. - list can be formatted with label: [x_min, y_min, x_max, y_max, label] or without label: [x_min, y_min, x_max, y_max] - array should be a 1-dimensional array of shape (4,)\n:param label: a list or str that has the class name or label for the object in the corresponding box.\nWorks with arrays and lists:\n\nBaseBx(annots)\n\nBaseBx(coords=[[14, 51, 71, 92]], label=[])\n\n\n\nb = BaseBx(annots, 'flower')\n\n\nb\n\nBaseBx(coords=[[14, 51, 71, 92]], label=['flower'])\n\n\n\nb.coords\n\n[[14, 51, 71, 92]]\n\n\nCalling the values attribute returns the labels along with the coordinates.\n\nb.values\n\n(#1) [[14, 51, 71, 92, 'flower']]\n\n\nBaseBx also exposes a method to calculate the Intersection Over Union (IOU):\n\nsource\n\n\nBaseBx.iou\n\n BaseBx.iou (other)\n\nCaclulates the Intersection Over Union (IOU) of the box w.r.t. another BaseBx. Returns the IOU only if the box is considered valid.\n\nb\n\nBaseBx(coords=[[14, 51, 71, 92]], label=['flower'])\n\n\nBaseBx is also pseudo-iterable (calling an iterator returns self itself and not the coordinates or labels).\n\nb = BaseBx(annots, 'flower')\n\n\nnext(b)\n\nBaseBx(coords=[[14, 51, 71, 92]], label=['flower'])\n\n\n\nfor b_ in b:\n    print(b_)\n\nWorking with multiple bounding boxes and annotaions is usually done with the help of MultiBx. MultiBx allows iteration.\n\nsource\n\n\nMultiBx\n\n MultiBx (coords, label:list=None)\n\nMultiBx represents a collection of bounding boxes as ndarrays. Objects of type MultiBx can be indexed into, which returns a BaseBx exposing a suite of box-bound operations. Multiple coordinates and labels of bounding boxes can be wrapped as a MultiBx using: mbx(coords, label). :param coords: can be nested coordinates of type list of lists/json records (lists of dicts)/ndarrays representing multiple boxes. If passing a list/json each index of the object should be of the following formats: - list can be formatted with label: [x_min, y_min, x_max, y_max, label] or without label: [x_min, y_min, x_max, y_max] - dict should be in pascal_voc format using the keys {“x_min”: 0, “y_min”: 0, “x_max”: 1, “y_max”: 1, “label”: ‘none’} If passing an ndarray, it should be of shape (N,4).\n:param label: a list of strs that has the class name or label for the object in the corresponding box.\nGenerate random coordinates:\n\nnp.random.seed(42)\nannots = [sorted([np.random.randint(100) for i in range(4)]) for j in range(3)]\nannots\n\n[[14, 51, 71, 92], [20, 60, 82, 86], [74, 74, 87, 99]]\n\n\nAll annotations are stored as a BaseBx in a container called MultiBx\n\nbxs = MultiBx(annots, ['apple', 'coke', 'tree'])\nbxs\n\nMultiBx(coords=[[14, 51, 71, 92], [20, 60, 82, 86], [74, 74, 87, 99]], label=['apple', 'coke', 'tree'])\n\n\nEach index reveals the stored coordinate as a BaseBx\n\nbxs[0]\n\nBaseBx(coords=[[14, 51, 71, 92]], label=['apple'])\n\n\nThey can also be iterated:\n\nnext(bxs)\n\nBaseBx(coords=[[14, 51, 71, 92]], label=['apple'])\n\n\nOr using list comprehension, properties of individual boxes can be extracted\n\n[b.area for b in bxs]\n\n[2337, 1612, 325]\n\n\n\nbxs[0].valid\n\nTrue\n\n\n\n\n\n[True, True]\n\n\n\nbxs[1].yolo()\n\n(#1) [[51.0, 73.0, 62, 26]]\n\n\n\nbxs[0].area\n\n2337\n\n\n\n[b_.area for b_ in bxs]\n\n[1612, 325]\n\n\nExtending BaseBx to also accept (json, dict) formatted coordinates and labels.\n\nsource\n\n\njbx\n\n jbx (coords=None, labels=None, keys=None)\n\nAlias of the JsonBx class to process json records into MultiBx or BaseBx objects exposing many validation methods\nAlso accepts keys as a list, otherwise uses voc_keys.\n\nannots = json.load(open('../data/annots.json'))\nannots\n\n[{'x_min': 150, 'y_min': 70, 'x_max': 270, 'y_max': 220, 'label': 'clock'},\n {'x_min': 10, 'y_min': 180, 'x_max': 115, 'y_max': 260, 'label': 'frame'}]\n\n\n\njbx(annots, keys=voc_keys)\n\n__JsonBx(coords=[[150, 70, 270, 220], [10, 180, 115, 260]], label=['clock', 'frame'])\n\n\nAlso accepts keys (for the dict) as a list, otherwise uses voc_keys.\n\nvoc_keys\n\n['x_min', 'y_min', 'x_max', 'y_max', 'label']\n\n\nMaking MultiBx work with lists with more than 4 items. It is a common practice to have the class label along with the coordinates. This classmethod is useful in such situations\n\nITER_TYPES\n\n(numpy.ndarray, list, fastcore.foundation.L)\n\n\n\nsource\n\n\nlbx\n\n lbx (coords=None, labels=None)\n\nAlias of the __ListBx class to process list into MultiBx or BaseBx objects exposing many validation methods\n\nannots = [[10, 20, 100, 200, 'apple'], [40, 50, 80, 90, 'coke'], ]\nannots\n\n[[10, 20, 100, 200, 'apple'], [40, 50, 80, 90, 'coke']]\n\n\n\nlbx(annots)\n\n__ListBx(coords=[[10, 20, 100, 200], [40, 50, 80, 90]], label=['apple', 'coke'])\n\n\n\nlbx(annots)[0]\n\nBaseBx(coords=[[10, 20, 100, 200]], label=['apple'])\n\n\nInserting classmethod to process lists and dicts in MultiBx.\n\nsource\n\n\nmbx\n\n mbx (coords=None, label=None, keys=None)\n\nAlias of the MultiBx class.\n\nsource\n\n\nMultiBx.multibox\n\n MultiBx.multibox (coords, label:list=None, keys:list=None)\n\nClassmethod for MultiBx. Same as mbx(coords, label). Calls classmethods of JsonBx and ListBx based on the type of coords passed.\n\nannots_list = annots\nannots_list\n\n[[10, 20, 100, 200, 'apple'], [40, 50, 80, 90, 'coke']]\n\n\n\nannots_json = json.load(open('../data/annots.json'))\nannots_json\n\n[{'x_min': 150, 'y_min': 70, 'x_max': 270, 'y_max': 220, 'label': 'clock'},\n {'x_min': 10, 'y_min': 180, 'x_max': 115, 'y_max': 260, 'label': 'frame'}]\n\n\nHow the class method works:\n\nt = explode_types(annots_list)  # get all types\nt\n\n{list: [{list: [int, int, int, int, str]}, {list: [int, int, int, int, str]}]}\n\n\n\nt[list][0]  # index into the nested list and call the right class\n\n{list: [int, int, int, int, str]}\n\n\n\nmbx(annots_json)\n\nMultiBx(coords=[[150, 70, 270, 220], [10, 180, 115, 260]], label=['clock', 'frame'])\n\n\n\nmbx(annots_list)\n\nMultiBx(coords=[[10, 20, 100, 200], [40, 50, 80, 90]], label=['apple', 'coke'])\n\n\n\nmbx(annots_json[0])\n\nMultiBx(coords=[[150, 70, 270, 220]], label=['clock'])\n\n\nChecking if it works with ndarrays\n\nnp.random.seed(42)\nannots = np.array([sorted([np.random.randint(100) for i in range(4)]) for j in range(3)])\nannots\n\narray([[14, 51, 71, 92],\n       [20, 60, 82, 86],\n       [74, 74, 87, 99]])\n\n\n\nmbx(annots)\n\nMultiBx(coords=[[14, 51, 71, 92], [20, 60, 82, 86], [74, 74, 87, 99]], label=[None, None, None])\n\n\nAllowing BaseBx to process a single dict and list directly.\n\nsource\n\n\nbbx\n\n bbx (coords=None, labels=None, keys=['x_min', 'y_min', 'x_max', 'y_max',\n      'label'])\n\nAlias of the BaseBx class.\n\nsource\n\n\nBaseBx.basebx\n\n BaseBx.basebx (coords, label:list=None, keys:list=['x_min', 'y_min',\n                'x_max', 'y_max', 'label'])\n\nClassmethod for BaseBx. Same as bbx(coords, label), made to work with other object types other than ndarray.\nRemember that BaseBx can only have one box coordinate and label at a time.\n\nannots_list\n\n[[10, 20, 100, 200, 'apple'], [40, 50, 80, 90, 'coke']]\n\n\nWhat does make_single_iterable do? It converts a single list or dict of coordinates into an iterable list that can be used by BaseBx.\n\nannots_list[0]\n\n[10, 20, 100, 200, 'apple']\n\n\n\nmake_single_iterable(annots_list[0], keys=voc_keys)\n\n((#1) [[10, 20, 100, 200]], ['apple'])\n\n\nThe class method makes it easier to directly call BaseBx without making the coordinates a list of list.\n\nbbx(annots_list[0])\n\nBaseBx(coords=[[10, 20, 100, 200]], label=['apple'])\n\n\n\nannots_list[0][:-1]\n\n[10, 20, 100, 200]\n\n\n\nbbx(annots_list[0][:-1])  # if label is not passed\n\nBaseBx(coords=[[10, 20, 100, 200]], label=[])\n\n\n\nbbx(annots_json[0])\n\nBaseBx(coords=[[150, 70, 270, 220]], label=['clock'])\n\n\n\n\nget_bx\nWhen in doubt, use get_bx.\n\nITER_TYPES\n\n(numpy.ndarray, list, fastcore.foundation.L)\n\n\n/mnt/data/projects/pybx/.venv/lib/python3.7/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section Raises\n  else: warn(msg)\n\nsource\n\nget_bx\n\n get_bx (coords, label=None)\n\nHelper function to check and call the correct type of Bx instance.\nChecks for the type of data passed and calls the respective class to generate a Bx instance. Currently only supports ndarray, list, dict, tuple, nested list, nested tuple.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncoords\nndarray, list, dict, tuple, nested list, nested tuple\n\nCoordinates of anchor boxes.\n\n\nlabel\nNoneType\nNone\nLabels for anchor boxes in order, by default None\n\n\nReturns\nBx\n\nAn instance of MultiBx, ListBx, BaseBx or JsonBx\n\n\n\nget_bx runs a bunch of if-else statements to call the right module when in doubt.\n\nannots_json\n\n[{'x_min': 150, 'y_min': 70, 'x_max': 270, 'y_max': 220, 'label': 'clock'},\n {'x_min': 10, 'y_min': 180, 'x_max': 115, 'y_max': 260, 'label': 'frame'}]\n\n\n\nget_bx(annots_json)\n\nMultiBx(coords=[[150, 70, 270, 220], [10, 180, 115, 260]], label=['clock', 'frame'])\n\n\n\nlen(annots_json[0])\n\n5\n\n\n\nget_bx([annots_json[0]])\n\nMultiBx(coords=[[150, 70, 270, 220]], label=['clock'])\n\n\n\nget_bx(annots_list)\n\nMultiBx(coords=[[10, 20, 100, 200], [40, 50, 80, 90]], label=['apple', 'coke'])\n\n\n\nget_bx([0, 1, 0, 1])\n\nBaseBx(coords=[[0, 1, 0, 1]], label=[])\n\n\nEnabling stacking of different boxes.\n\nsource\n\n\nadd_bxs\n\n add_bxs (b1, b2)\n\nAlias of stack_bxs().\n\nsource\n\n\nstack_bxs\n\n stack_bxs (b1, b2)\n\nMethod to stack two Bx-types together. Similar to __add__ of BxTypes but avoids UserWarning. :param b1: :param b2: :return:\nsummary\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nb1\nBx, MultiBx\nAnchor box coordinates Bx\n\n\nb2\nBx, MultiBx\nAnchor box coordinates Bx\n\n\nReturns\nMultiBx\nStacked anchor box coordinates of MultiBx type.\n\n\n\n\nb\n\nBaseBx(coords=[[14, 51, 71, 92]], label=['flower'])\n\n\nInternally this is what is done to stack them:\n\nbxs.coords + b.coords, bxs.label + b.label\n\n([[14, 51, 71, 92], [20, 60, 82, 86], [74, 74, 87, 99], [14, 51, 71, 92]],\n (#4) ['apple','coke','tree','flower'])\n\n\n\nbxs + b\n\nMultiBx(coords=[[14, 51, 71, 92], [20, 60, 82, 86], [74, 74, 87, 99], [14, 51, 71, 92]], label=['apple', 'coke', 'tree', 'flower'])\n\n\nAdding a MultiBx to a BaseBx makes the new set of coordinates a MultiBx, so a BxViolation warning is issued if this was not intended.\n\nb + bxs\n\n/home/gg/data/pybx/.venv/lib/python3.7/site-packages/ipykernel_launcher.py:19: BxViolation: Change of object type imminent if trying to add <class '__main__.BaseBx'>+<class '__main__.MultiBx'>. Use <class '__main__.MultiBx'>+<class '__main__.BaseBx'> instead or basics.stack_bxs().\n\n\nMultiBx(coords=[[14, 51, 71, 92], [14, 51, 71, 92], [20, 60, 82, 86], [74, 74, 87, 99]], label=['flower', 'apple', 'coke', 'tree'])\n\n\n\nstack_bxs(b, bxs)\n\nMultiBx(coords=[[14, 51, 71, 92], [14, 51, 71, 92], [20, 60, 82, 86], [74, 74, 87, 99]], label=['flower', 'apple', 'coke', 'tree'])\n\n\nTo avoid the BxViolation, use the method stack_bxs.\n\nstack_bxs(bxs, b)\n\nMultiBx(coords=[[14, 51, 71, 92], [20, 60, 82, 86], [74, 74, 87, 99], [14, 51, 71, 92]], label=['apple', 'coke', 'tree', 'flower'])"
  },
  {
    "objectID": "utils.html",
    "href": "utils.html",
    "title": "Utilities",
    "section": "",
    "text": "source\n\nvalidate_boxes\n\n validate_boxes (coords, image_sz, feature_sz, clip=True,\n                 min_visibility=0.25)\n\nValidate calculated anchor box coords. :param coords: anchor box coordinates :param image_sz: tuple of (width, height) of an image :param feature_sz: tuple of (width, height) of a channel :param clip: whether to apply np.clip :param min_visibility: minimum visibility dictates the condition for a box to be considered valid. The value corresponds to the ratio of expected area to the calculated area after clipping to image dimensions. :return: anchor box coordinates in [pascal_voc] format\n\nsource\n\n\nget_edges\n\n get_edges (image_sz:tuple, feature_sz:tuple, op='noop')\n\nGenerate offsetted top (x_min, y_min) or bottom edges (x_max, y_max) coordinates of a given feature size based on op. if op is noop, gets the top edges. if op is add, gets the bottom edges. :param op: operation for calculating edges, either ‘add’ ‘sub’ ‘noop’ :param image_sz: tuple of (W, H) of an image :param feature_sz: tuple of (W, H) of a channel :return: offsetted edges of each feature\n\nnp.random.seed(42)\ncoords = np.random.random((100, 4))\ncoords[:2]\n\narray([[0.37454012, 0.95071431, 0.73199394, 0.59865848],\n       [0.15601864, 0.15599452, 0.05808361, 0.86617615]])\n\n\n\nget_bx(coords)[0]._coords\n\narray([0.37454012, 0.95071431, 0.73199394, 0.59865848])\n\n\n\nvalidate_boxes(coords, (1, 1), (1, 1), clip=True, min_visibility=0.25)\n\n(#14) [[0.07455064367977082, 0.9868869366005173, 0.7722447692966574, 0.1987156815341724],[0.8631034258755935, 0.6232981268275579, 0.3308980248526492, 0.06355835028602363],[0.907566473926093, 0.24929222914887494, 0.41038292303562973, 0.7555511385430487],[0.8074401551640625, 0.8960912999234932, 0.3180034749718639, 0.11005192452767676],[0.22793516254194168, 0.4271077886262563, 0.8180147659224931, 0.8607305832563434],[0.040775141554763916, 0.5908929431882418, 0.6775643618422824, 0.016587828927856152],[0.3410663510502585, 0.11347352124058907, 0.9246936182785628, 0.877339353380981],[0.5296505783560065, 0.24185229090045168, 0.09310276780589921, 0.8972157579533268],[0.6420316461542878, 0.08413996499504883, 0.16162871409461377, 0.8985541885270792],[0.6064290596595899, 0.009197051616629648, 0.1014715428660321, 0.6635017691080558]...]\n\n\n\nsource\n\n\nas_tuple\n\n as_tuple (x)\n\nGet x as a tuple (x, x) if not already a tuple.\n\n\n\n\nType\nDetails\n\n\n\n\nx\n(int, tuple)\nItem that needs to be converted to a tuple.\n\n\n\n\nas_tuple(2)\n\n(2, 2)"
  },
  {
    "objectID": "ops.html",
    "href": "ops.html",
    "title": "Operations",
    "section": "",
    "text": "source\n\nupdate_keys\n\n update_keys (annots:dict, default_keys=None)\n\nModify the default class label key that the JsonBx method looks for. By default, JsonBx uses the parameter ops.voc_keys and looks for the key “label” in the dict. If called, update_keys looks inside the parameter ops.label_keys for matching key in the passed annots and uses this as the key to identify class label. Fixes #3. :param annots: dictionary of annotations :param default_keys: voc_keys by default :return: new keys with updated label key\n\nsource\n\n\nintersection_box\n\n intersection_box (b1:list, b2:list)\n\nReturn the box that intersects two boxes in pascal_voc format.\n\nsource\n\n\nnamed_idx\n\n named_idx (ncoords:int, sfx:str='')\n\nReturn a list of indices as str matching the array size, suffixed with sfx :param ncoords: number of coordinates :param sfx: suffix to be added to the index :return: list of strings\n\nsource\n\n\nmake_single_iterable\n\n make_single_iterable (x, keys=['x_min', 'y_min', 'x_max', 'y_max',\n                       'label'])\n\nMethod to convert a single dict or a list to an array. :param x: dict with keys {“x_min”: 0, “y_min”: 0, “x_max”: 1, “y_max”: 1, “label”: ‘none’} :return: coords as ndarray, label as list\n\nsource\n\n\nget_op\n\n get_op (op:str)\n\nGiven a string of aps.__ops__, return the function reference.\n\nsource\n\n\nnoop\n\n noop (x, _)\n\nPerform no operation (“no-op”) on x. :param x: input object 1 :param _: input object 2 :return: input object 1\n\nsource\n\n\nmul\n\n mul (x, y)\n\nMultiply two objects.\n\nsource\n\n\nsub\n\n sub (x, y)\n\nSubtract two objects.\n\nsource\n\n\nadd\n\n add (x, y)\n\nAdd two objects."
  },
  {
    "objectID": "sample.html",
    "href": "sample.html",
    "title": "Samples",
    "section": "",
    "text": "source\n\nget_given_array\n\n get_given_array (image_arr, **kwargs)\n\nGet the image_array setup for visualisation. :param image_arr: image nparray :return: reference to protected _get_given_array()\n\nsource\n\n\nget_example\n\n get_example (image_sz:tuple, **kwargs)\n\nGet an example image from the pth given for some image size for a feature size :param image_sz: required image size (will resize the original image) :return: reference to protected _get_example()"
  },
  {
    "objectID": "vis.html",
    "href": "vis.html",
    "title": "Visualizations",
    "section": "",
    "text": "Loading from disk\nLoad a sample image from the data directory ../data/image.jpg and resize to (200, 200, 3)\n\nim, ann, lgt, clr = get_example(image_sz=(200, 200, 3), pth='../data', img_fn='image.jpg')\n\nim is the image of a clock and a frame, ann are the annotations for the image in json format, lgt are logits (activations from a layer) which can be displayed on top of the image, clr is a dict representing the colors to use for the different annotation keys.\n\nann, lgt, clr\n\n([{'x_min': 100.0,\n   'y_min': 46.666666666666664,\n   'x_max': 180.0,\n   'y_max': 146.66666666666666,\n   'label': 'clock'},\n  {'x_min': 6.666666666666667,\n   'y_min': 120.0,\n   'x_max': 76.66666666666667,\n   'y_max': 173.33333333333334,\n   'label': 'frame'}],\n None,\n {'frame': 'blue', 'clock': 'green'})\n\n\n\n_ = plt.imshow(im)\n\n\n\n\nStore the annotations as a MultiBx object.\n\nget_bx(ann)\n\nMultiBx(coords=[[100.0, 46.666666666666664, 180.0, 146.66666666666666], [6.666666666666667, 120.0, 76.66666666666667, 173.33333333333334]], label=['clock', 'frame'])\n\n\n\nsource\n\n\ndraw\n\n draw (img:numpy.ndarray, bbox:list, logits=None, alpha=0.4, **kwargs)\n\nMethod to draw an image, box and logits overlayed if passed. :param img: the image array, expects a numpy array :param bbox: list of bounding boxes in json format :param logits: activations that should be overlayed from a neural network (no checks) :param kwargs: kwargs for draw_boxes() :param alpha: same as alpha for matplotlib :return: current axis\n\nsource\n\n\ndraw_boxes\n\n draw_boxes (img:numpy.ndarray, bbox:list, title=None, ax=None,\n             figsize=(5, 4), color='yellow', no_ticks=False, xo=0, yo=0,\n             squeeze=False, **kwargs)\n\nMethod to draw bounding boxes in an image, can handle multiple bboxes :param figsize: sige of figure :param img: the image array, expects a numpy array :param bbox: list of bounding boxes in json format :param title: image title :param ax: which axis if already present :param yo: y offset for placement of text :param xo: x offset for placement of text :param color: text color or dict of colors for each label as a dict :param no_ticks: whether to set axis ticks off :param squeeze: squeeze axis :return: ax with image\n\nsource\n\n\ndraw_rectangle\n\n draw_rectangle (ax, coords, color='white')\n\nDraw a rectangle using matplotlib patch. :param ax: axis :param coords: coordinates in coco format :param color: text color :return: ax object\n\nsource\n\n\ndraw_text\n\n draw_text (ax, xy:tuple, label:str, size=12, color='white', xo=0, yo=0)\n\nWrite text around boxes. :param ax: axis object :param xy: relative ax coordinates x, y to draw the text :param label: label for box :param size: font size :param yo: y offset for placement of text :param xo: x offset for placement of text :param color: text color :return: ax object\n\nsource\n\n\nget_extents\n\n get_extents (shape)\n\nGet extent parameter of the image.\n\nsource\n\n\nget_color\n\n get_color (color, label=None, default_color='white')\n\nGet colors from color dict for a given label. If label=None, return default_color. :param color: dict of key, value pairs where key is label, value is color :param label: the label for which color is needed :param default_color: :return: str that contains color\n\nsource\n\n\ndraw_outline\n\n draw_outline (obj, linewidth:int)\n\nMake outlines around to object edges for visibility in light backgrounds :param obj: plt objects like text or rectangle :param linewidth: width of the stroke :return: plt object\n\nann\n\n[{'x_min': 100.0,\n  'y_min': 46.666666666666664,\n  'x_max': 180.0,\n  'y_max': 146.66666666666666,\n  'label': 'clock'},\n {'x_min': 6.666666666666667,\n  'y_min': 120.0,\n  'x_max': 76.66666666666667,\n  'y_max': 173.33333333333334,\n  'label': 'frame'}]\n\n\nDrawing random box by passing coordinates as a list.\n\ndraw(im, [[20, 20, 80, 80]])\n\n<AxesSubplot:>\n\n\n\n\n\nDrawing random box by passing coordinates as a list along with label.\n\ndraw(im, [[20, 20, 80, 80, 'random']], color={'random': 'blue'})\n\n<AxesSubplot:>\n\n\n\n\n\n\ndraw(im, [{'x_min': 50, 'y_min': 30, 'x_max':100, 'y_max':120, 'label':'random'}], \\\n    color={'random': 'green'})\n\n<AxesSubplot:>\n\n\n\n\n\nTo display the calculated anchor boxes or any other type of bounding boxes, pybx offers the vis.VisBx class. First, vis.VisBx initializes all the params for the image and loads its annotations (if available). Upon calling the show() method on the instantiated VisBx object with our predicted annotations or anchor boxes, everything gets displayed.\n\nsource\n\n\nVisBx\n\n VisBx (image_arr=None, image_sz=None, sample=False, **kwargs)\n\nVisBx is used to visualize the bounding boxes. The image on of which the bounding boxes are to be drawn can be instantiated with VisBx() if needed. Calling the show() method of the VisBx() instance accepts bounding box coordinates and labels that are to be shown. The boxes can be provided as any of the internal objects (MultiBx, BaseBx, …) or as any other raw format accepted by the internal objects.\nDisplaying image array and annotations object: This is the default approach used by VisBx(). If no arguments are passed, a tuple denoting the size for random noise random_img_sz=(100, 100, 1) is expected. Some arguments: :param image_arr: image array of shape (H, W, C). If None, it is set to a random noise image of image_sz=(100,100,3) by default. :param annots: annotations is any accepted format (see above).\nDisplaying from image and annotations file: To load and display the image, set sample=True. Some argmuments: :param ann_fn: annotations file name, default annots.json :param img_fn: image file name, default image.jpg :param load_ann: whether to load ann_fn or just the img_fn. If False, an empty annotations dict is returned: dict(zip(voc_keys, [0, 0, 1, 1, ''])) :param pth: path to find ann_fn and img_fn, default . :param image_sz: size to resize the loaded image a different size (annotations scaled automatically)\nCommon parameters: :param color: A dict of color can be passed to assign specific color to a specific label in the image: color = {'frame': 'blue', 'clock': 'green'} :param logits: Logits as ndarray that should be overlayed on top of the image or bool to generate random logits. :param feature_sz: Feature size to generate random logits if logits is not None.\n\n\nDisplay image array (default behaviour)\nTo display an image array (shape of W, H, C) directly, instead of loading from disk, pass an ndarray to the image_arr argument. If available, also provide the annots in any supported format. Displaying calculated anchors with a random image:\n\nanchor_boxes, anchor_labels = bx(200, 3, 1)\n\n\nv = VisBx(image_arr=np.random.random((200, 200, 3)))  # a 200x200 image is generated\nv.show(anchor_boxes, anchor_labels)\n\n<AxesSubplot:>\n\n\n\n\n\n\nv = VisBx(image_arr=np.random.random((10, 10, 3)), image_sz=(200,200, 3))  # a 10x10 will be resized to 200x200\nv.show(anchor_boxes, anchor_labels)\n\n<AxesSubplot:>\n\n\n\n\n\n\n\nLoad image and show annots\nDisplaying calculated anchors with a sample image.\n\nv = VisBx(pth='../data/', img_fn='image.jpg', image_sz=(200,200, 3))\nv.show(anchor_boxes, anchor_labels)\n\n<AxesSubplot:>\n\n\n\n\n\n\n\nCustomize colors\nTo customize the box colors, pass a dict color with the annotation name as key and color as value. In the example below an anchor box color is changed to red using its label a_3x3_1.0_3 along with the annotations provided read from file.\n\nv.show(anchor_boxes, anchor_labels, color={'a_3x3_1.0_3': 'red', 'frame': 'green', 'clock': 'green'})\n\n<AxesSubplot:>"
  },
  {
    "objectID": "excepts.html",
    "href": "excepts.html",
    "title": "Exceptions",
    "section": "",
    "text": "source\n\nBxViolation\nViolation of Bx properties.\n\nsource\n\n\nNoIntersection\nNo intersection of boxes occur."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "pybx",
    "section": "",
    "text": "A simple python package to generate anchor boxes for multi-box object detection models.\nCalculated anchor boxes are in pascal_voc format by default.\n\n\nInstallation\npip install pybx\n\n\nUsage\nTo calculate the anchor boxes for a single feature size and aspect ratio, given the image size:\n\nfrom pybx import anchor, ops\n\nimage_sz = (300, 300)\nfeature_sz = (10, 10)\nasp_ratio = 1/2.\n\ncoords, labels = anchor.bx(image_sz, feature_sz, asp_ratio)\n\n100 anchor boxes of asp_ratio 0.5 is generated along with unique labels:\n\nlen(coords), len(labels)\n\n(100, 100)\n\n\nThe anchor box labels are especially useful, since they are pretty descriptive:\n\ncoords[-1], labels[-1]\n\n([274.3933982822018, 263.7867965644036, 295.6066017177982, 300.0],\n 'a_10x10_0.5_99')\n\n\nTo calculate anchor boxes for multiple feature sizes and aspect ratios, we use anchor.bxs instead:\n\nfeature_szs = [(10, 10), (8, 8)]\nasp_ratios = [1., 1/2., 2.]\n\ncoords, labels = anchor.bxs(image_sz, feature_szs, asp_ratios)\n\nAll anchor boxes are returned as ndarrays of shape (N,4) where N is the number of boxes.\nThe box labels are even more important now, since they help you uniquely identify to which feature map size or aspect ratios they belong to.\n\ncoords[101], labels[101]\n\n(array([34.39339828,  0.        , 55.60660172, 36.21320344]), 'a_10x10_0.5_1')\n\n\n\ncoords[-1], labels[-1]\n\n(array([254.73349571, 267.99174785, 300.        , 294.50825215]),\n 'a_8x8_2.0_63')\n\n\n\nMultiBx methods\nBox coordinates (with/without labels) in any format (usually ndarray, list, json, dict) can be instantialized as a MultiBx, exposing many useful methods and attributes of MultiBx. For example to calculate the area of each box iteratively:\n\nfrom pybx.basics import * \n# passing anchor boxes and labels from anchor.bxs()\nprint(coords.shape)\n\nboxes = mbx(coords, labels)\ntype(boxes)\n\n(492, 4)\n\n\npybx.basics.MultiBx\n\n\n\nlen(boxes)\n\n492\n\n\n\nareas = [b.area for b in boxes]\n\nEach annotation in the MultiBx object boxes is also a BaseBx with its own set of methods and properties.\n\nboxes[-1]\n\nBaseBx(coords=[[254.73349570550448, 267.9917478527522, 300.0, 294.5082521472478]], label=['a_8x8_2.0_63'])\n\n\n\nboxes[-1].coords, boxes[-1].label\n\n((#1) [[254.73349570550448, 267.9917478527522, 300.0, 294.5082521472478]],\n (#1) ['a_8x8_2.0_63'])\n\n\nMultiBx objects can also be “added” which stacks them vertically to create a new MultiBx object:\n\nboxes_true = mbx(coords_json)    # annotation as json records\nlen(boxes_true)\n\n2\n\n\n\nboxes_anchor = mbx(coords_numpy) # annotation as ndarray\nlen(boxes_anchor)\n\n492\n\n\n\nboxes_true\n\nMultiBx(coords=[[150, 70, 270, 220], [10, 180, 115, 260]], label=['clock', 'frame'])\n\n\n\nboxes = boxes_true + boxes_anchor + boxes_true\n\n\nlen(boxes)\n\n496"
  }
]