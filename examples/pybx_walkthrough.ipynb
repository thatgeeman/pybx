{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ecf40bc",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/thatgeeman/pybx/blob/master/nbs/pybx_walkthrough.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hS3q4tgTIIae",
   "metadata": {
    "id": "hS3q4tgTIIae"
   },
   "source": [
    ">⚠ Note: walkthrough for v0.2.1 ⚠\n",
    ">\n",
    ">run `! pip freeze | grep pybx` to see the installed version. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904b9817",
   "metadata": {
    "id": "904b9817",
    "papermill": {
     "duration": 0.022224,
     "end_time": "2022-01-15T18:00:10.052411",
     "exception": false,
     "start_time": "2022-01-15T18:00:10.030187",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PyBx\n",
    "\n",
    "PyBx is a simple python package to generate anchor boxes (aka default/prior boxes) for object detection tasks. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da615c1e",
   "metadata": {
    "id": "da615c1e",
    "papermill": {
     "duration": 0.021105,
     "end_time": "2022-01-15T18:00:25.594171",
     "exception": false,
     "start_time": "2022-01-15T18:00:25.573066",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SSD for Object Detection\n",
    "\n",
    "This walkthrough is build around the [Single-Shot Detection (SSD)](https://arxiv.org/pdf/1512.02325.pdf) algorithm. The SSD can be imagined as an encoder-decoder model architecture, where the input image is fed into a `backbone` (encoder) to generate inital features, which then goes through a series of 2D convolution layers (decoders) to perform further feature extraction/prediction tasks at each layer. For a single image, each layer in the decoder produces a total of `N x (4 + C)` predictions. Here `C` is the number of classes (plus one for `background` class) in the detection task and 4 comes from the corners of the rectangular bounding box. \n",
    "\n",
    "### Usage of the term Feature/Filter/Channel\n",
    "\n",
    "Channel: RGB dimensione, also called a Filter\n",
    "\n",
    "Feature: (W,H) of a single channel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5a9476",
   "metadata": {
    "id": "9d5a9476",
    "papermill": {
     "duration": 0.022256,
     "end_time": "2022-01-15T18:00:25.639322",
     "exception": false,
     "start_time": "2022-01-15T18:00:25.617066",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Example case \n",
    "For this example, we assume that our input image is a single channel image is of shape `[B, 3, 300, 300]` where `B` is the batch size. Assuming that a pretrained `VGG-16` is our model `backbone`, the output feature shape would be: `[B, 512, 37, 37]`. Meaning that, 512 channels of shape `[37, 37]` were extracted from each image in the batch. In the subsequent decoder layers, for simplicity we double the channels while halving the feature shape using `3x3` `stride=2` convolutions (except for first decoder layer where convolution is not applied). This results in the following shapes:\n",
    "\n",
    "```python\n",
    "torch.Size([-1, 512, 37, 37])  # inp from vgg-16 encoder\n",
    "torch.Size([-1, 1024, 18, 18]) # first layer logits\n",
    "torch.Size([-1, 2048, 8, 8])   # second layer logits\n",
    "torch.Size([-1, 4096, 3, 3])   # third layer logits\n",
    "```\n",
    "\n",
    "<img src=\"https://lilianweng.github.io/lil-log/assets/images/SSD-box-scales.png\" width=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb66a0ee",
   "metadata": {
    "id": "fb66a0ee",
    "papermill": {
     "duration": 0.022428,
     "end_time": "2022-01-15T18:00:25.685695",
     "exception": false,
     "start_time": "2022-01-15T18:00:25.663267",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Sample image\n",
    "Image obtained from USC-SIPI Image Database. \n",
    "The USC-SIPI image database is a collection of digitized images. It is maintained primarily to support research in image processing, image analysis, and machine vision. The first edition of the USC-SIPI image database was distributed in 1977 and many new images have been added since then."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113beae5",
   "metadata": {},
   "source": [
    "Set working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a867277f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"DATADIR\"] = \"../data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bbffab",
   "metadata": {},
   "source": [
    "Install package if not already present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c349f6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "EXISTS=$(pip freeze | grep pybx | wc -l)\n",
    "date\n",
    "if [ $EXISTS -eq 0 ]\n",
    "then \n",
    "    pip install pybx\n",
    "else\n",
    "    pip freeze | grep pybx\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28fa8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo $DATADIR\n",
    "mkdir -p $DATADIR\n",
    "wget -q -O $DATADIR/image.jpg 'https://sipi.usc.edu/database/download.php?vol=misc&img=5.1.12'\n",
    "ls $DATADIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa5c76a",
   "metadata": {
    "id": "baa5c76a",
    "papermill": {
     "duration": 0.021061,
     "end_time": "2022-01-15T18:00:26.983030",
     "exception": false,
     "start_time": "2022-01-15T18:00:26.961969",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## About anchor Boxes\n",
    "\n",
    "We are expected to provide our models with \"good\" anchor (aka default/prior) boxes. Strong opinion: Our model is [only as good as the initial anchor boxes](https://towardsdatascience.com/anchor-boxes-the-key-to-quality-object-detection-ddf9d612d4f9) that we generate. Inorder to improve the coverage of our model, we tend to add additional anchor boxes of different aspect ratios. Now, for a single image, each layer in the decoder produces a total of `N x A x (4 + C)` predictions. Here `A` is the number of aspect ratios to generate additional anchor boxes.\n",
    "\n",
    "### Task description\n",
    "\n",
    "Our aim is to find the maximum number of anchor boxes in varying sizes `feature_szs` and aspect ratios `asp_ratios` across the entire image. We apply no filtering to get rid of low (IOU) anchors.\n",
    "\n",
    "<img src=\"https://lilianweng.github.io/lil-log/assets/images/SSD-framework.png\" width=\"600\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca26b3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T18:00:27.033141Z",
     "iopub.status.busy": "2022-01-15T18:00:27.032418Z",
     "iopub.status.idle": "2022-01-15T18:00:27.034948Z",
     "shell.execute_reply": "2022-01-15T18:00:27.034375Z",
     "shell.execute_reply.started": "2022-01-15T17:50:58.517734Z"
    },
    "id": "aca26b3f",
    "papermill": {
     "duration": 0.029729,
     "end_time": "2022-01-15T18:00:27.035099",
     "exception": false,
     "start_time": "2022-01-15T18:00:27.005370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_szs = [(37,37), (18,18), (8,8), (3,3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45dec8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T18:00:27.087113Z",
     "iopub.status.busy": "2022-01-15T18:00:27.086341Z",
     "iopub.status.idle": "2022-01-15T18:00:27.089033Z",
     "shell.execute_reply": "2022-01-15T18:00:27.088462Z",
     "shell.execute_reply.started": "2022-01-15T17:50:58.524059Z"
    },
    "id": "f45dec8a",
    "papermill": {
     "duration": 0.033227,
     "end_time": "2022-01-15T18:00:27.089177",
     "exception": false,
     "start_time": "2022-01-15T18:00:27.055950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "asp_ratios = [1/2., 1., 2.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07049cce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T18:00:27.138756Z",
     "iopub.status.busy": "2022-01-15T18:00:27.137815Z",
     "iopub.status.idle": "2022-01-15T18:00:27.141964Z",
     "shell.execute_reply": "2022-01-15T18:00:27.142526Z",
     "shell.execute_reply.started": "2022-01-15T17:50:58.536683Z"
    },
    "id": "07049cce",
    "papermill": {
     "duration": 0.03305,
     "end_time": "2022-01-15T18:00:27.142765",
     "exception": false,
     "start_time": "2022-01-15T18:00:27.109715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from operator import __mul__\n",
    "n_boxes = sum([__mul__(*f) for f in feature_szs]) \n",
    "print(f'minimum anchor boxes with 1 aspect ratio: {n_boxes}')\n",
    "print(f'minimum anchor boxes with {len(asp_ratios)} aspect ratios: {n_boxes*len(asp_ratios)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd59928b",
   "metadata": {
    "id": "cd59928b",
    "papermill": {
     "duration": 0.021216,
     "end_time": "2022-01-15T18:00:27.185571",
     "exception": false,
     "start_time": "2022-01-15T18:00:27.164355",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loading an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bd5786",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T18:00:27.234280Z",
     "iopub.status.busy": "2022-01-15T18:00:27.233506Z",
     "iopub.status.idle": "2022-01-15T18:00:27.237653Z",
     "shell.execute_reply": "2022-01-15T18:00:27.237065Z",
     "shell.execute_reply.started": "2022-01-15T17:50:58.548577Z"
    },
    "id": "43bd5786",
    "papermill": {
     "duration": 0.031417,
     "end_time": "2022-01-15T18:00:27.237814",
     "exception": false,
     "start_time": "2022-01-15T18:00:27.206397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b84a839",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = Path(os.environ[\"DATADIR\"])\n",
    "datadir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f2cd48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T18:00:27.288229Z",
     "iopub.status.busy": "2022-01-15T18:00:27.287472Z",
     "iopub.status.idle": "2022-01-15T18:00:27.586666Z",
     "shell.execute_reply": "2022-01-15T18:00:27.587184Z",
     "shell.execute_reply.started": "2022-01-15T17:50:58.56001Z"
    },
    "id": "70f2cd48",
    "papermill": {
     "duration": 0.328678,
     "end_time": "2022-01-15T18:00:27.587377",
     "exception": false,
     "start_time": "2022-01-15T18:00:27.258699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "im = cv2.cvtColor(cv2.imread((datadir/\"image.jpg\").as_posix()), cv2.COLOR_BGR2RGB)\n",
    "im = cv2.resize(im, (300,300), interpolation=cv2.INTER_NEAREST)\n",
    "_ = plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10ef9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "im.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cf3e01",
   "metadata": {
    "id": "a8cf3e01",
    "papermill": {
     "duration": 0.024124,
     "end_time": "2022-01-15T18:00:27.634480",
     "exception": false,
     "start_time": "2022-01-15T18:00:27.610356",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We also make 2 truth bounding boxes `bbox` for this image around the clock and the photoframe in `pascal voc` format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70fb639",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T18:00:27.686393Z",
     "iopub.status.busy": "2022-01-15T18:00:27.685704Z",
     "iopub.status.idle": "2022-01-15T18:00:27.692496Z",
     "shell.execute_reply": "2022-01-15T18:00:27.693137Z",
     "shell.execute_reply.started": "2022-01-15T17:51:00.308247Z"
    },
    "id": "f70fb639",
    "papermill": {
     "duration": 0.03505,
     "end_time": "2022-01-15T18:00:27.693319",
     "exception": false,
     "start_time": "2022-01-15T18:00:27.658269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bbox = [dict(x_min=150, y_min=70, x_max=270, y_max=220, label='clock'),\n",
    "        dict(x_min=10, y_min=180, x_max=115, y_max=260, label='frame'),]\n",
    "bbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a20b85",
   "metadata": {
    "id": "14a20b85",
    "papermill": {
     "duration": 0.022688,
     "end_time": "2022-01-15T18:00:27.740432",
     "exception": false,
     "start_time": "2022-01-15T18:00:27.717744",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Save annotations as a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec071141",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T18:00:27.792021Z",
     "iopub.status.busy": "2022-01-15T18:00:27.791162Z",
     "iopub.status.idle": "2022-01-15T18:00:27.795691Z",
     "shell.execute_reply": "2022-01-15T18:00:27.796356Z",
     "shell.execute_reply.started": "2022-01-15T17:51:00.968052Z"
    },
    "id": "ec071141",
    "papermill": {
     "duration": 0.032885,
     "end_time": "2022-01-15T18:00:27.796558",
     "exception": false,
     "start_time": "2022-01-15T18:00:27.763673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(datadir/'annots.json', 'w') as f:\n",
    "  f.write(json.dumps(bbox))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TkcjCFudcz6T",
   "metadata": {
    "id": "TkcjCFudcz6T"
   },
   "outputs": [],
   "source": [
    "type(bbox[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f0077f",
   "metadata": {
    "id": "f6f0077f",
    "papermill": {
     "duration": 0.022644,
     "end_time": "2022-01-15T18:00:27.842466",
     "exception": false,
     "start_time": "2022-01-15T18:00:27.819822",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Using PyBx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f18f544",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T18:00:27.893224Z",
     "iopub.status.busy": "2022-01-15T18:00:27.891819Z",
     "iopub.status.idle": "2022-01-15T18:00:28.475204Z",
     "shell.execute_reply": "2022-01-15T18:00:28.474369Z",
     "shell.execute_reply.started": "2022-01-15T17:51:01.782431Z"
    },
    "id": "4f18f544",
    "papermill": {
     "duration": 0.609979,
     "end_time": "2022-01-15T18:00:28.475425",
     "exception": false,
     "start_time": "2022-01-15T18:00:27.865446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pybx import anchor\n",
    "\n",
    "image_sz = (300, 300, 3)  # W, H, C\n",
    "feature_sz = (3, 3)       # number of features along W, H\n",
    "asp_ratio = 1.            # aspect ratio of the anchor box\n",
    "\n",
    "anchors, labels = anchor.bx(image_sz, feature_sz, asp_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EXuXNLjfGELR",
   "metadata": {
    "id": "EXuXNLjfGELR"
   },
   "source": [
    "There are several ways to visualize the anchors. First we import the `vis` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qZr1MEZaf6sv",
   "metadata": {
    "id": "qZr1MEZaf6sv"
   },
   "outputs": [],
   "source": [
    "from pybx import vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Y3l3CQlXFwFO",
   "metadata": {
    "id": "Y3l3CQlXFwFO"
   },
   "outputs": [],
   "source": [
    "bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dIJ2xnPF-Gk",
   "metadata": {
    "id": "6dIJ2xnPF-Gk"
   },
   "outputs": [],
   "source": [
    "image_sz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef586ac1",
   "metadata": {},
   "source": [
    "### Visualizing the locally stored `image.png` with provided bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240ae95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "im.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccccb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baec8a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_arr = np.array(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb983075",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "v = vis.VisBx(image_arr=image_arr, \n",
    "              annots=bbox, \n",
    "              color={'frame':'red', 'clock':'blue'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc14a533",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "v.show()  # without any arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1888a86",
   "metadata": {},
   "source": [
    "Pass arguments to `show` method to overlay with calculated anchor boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0f4a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "v.show(anchors, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1f9ace",
   "metadata": {},
   "source": [
    "### Using the `sample=True` parameter to load a file \n",
    "By default it looks in the current path `pth=\".\"` for an image file `img_fn=\"image.png\"` and annotations file `ann_fn=\"annots.json\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78abcd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EL-bnvwsfxiL",
   "metadata": {
    "id": "EL-bnvwsfxiL"
   },
   "outputs": [],
   "source": [
    "v = vis.VisBx(image_sz=(300,300,3), \n",
    "              color={'frame':'red', 'clock':'blue'}, \n",
    "              img_fn=datadir/'image.jpg',\n",
    "              ann_fn=datadir/'annots.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e187c036",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "v.show(anchors, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15416720",
   "metadata": {},
   "source": [
    "### Using randomly generated noise as `image_arr`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CQ5vnwYxGF0P",
   "metadata": {
    "id": "CQ5vnwYxGF0P",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "v = vis.VisBx(image_sz=(300,300,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd8f994",
   "metadata": {},
   "outputs": [],
   "source": [
    "v.show(anchors, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff410bf",
   "metadata": {
    "id": "aff410bf",
    "papermill": {
     "duration": 0.032702,
     "end_time": "2022-01-15T18:00:28.538763",
     "exception": false,
     "start_time": "2022-01-15T18:00:28.506061",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The boxes in white are the anchor boxes. We can hightlight them with a different color by looking up specific box labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IWD8Q-kNGVfU",
   "metadata": {
    "id": "IWD8Q-kNGVfU"
   },
   "outputs": [],
   "source": [
    "anchors.shape, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tP3u48UtGYMZ",
   "metadata": {
    "id": "tP3u48UtGYMZ"
   },
   "source": [
    "We see there are 9 labels and box coordinates reported by `anchor.bx()` for our `feature_sz=3x3` and single `asp_ratio`. Once instantiated as a `MultiBx`, we can use the `mbx()` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j0UIn9crIGhu",
   "metadata": {
    "id": "j0UIn9crIGhu"
   },
   "outputs": [],
   "source": [
    "from pybx.basics import *\n",
    "\n",
    "b = mbx(anchors, labels)  # instantiates MultiBx for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naYNwM2glCXS",
   "metadata": {
    "id": "naYNwM2glCXS"
   },
   "outputs": [],
   "source": [
    "type(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_6r36yD0I63O",
   "metadata": {
    "id": "_6r36yD0I63O"
   },
   "source": [
    "We can iterate over a `MultiBx` object using list comprehension to understand the internal checks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Z9hMXGCqItdj",
   "metadata": {
    "id": "Z9hMXGCqItdj"
   },
   "outputs": [],
   "source": [
    "[(i, b_.valid()) for i, b_ in enumerate(b)]  # only valid boxes shown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-86Sb7XgMFMm",
   "metadata": {
    "id": "-86Sb7XgMFMm"
   },
   "source": [
    "`b_.valid()` returned `True` meaning that the box is considered valid. \n",
    "\n",
    "We can also calculate the areas of these boxes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3IrS93WdlcqA",
   "metadata": {
    "id": "3IrS93WdlcqA"
   },
   "source": [
    "Each box `b_` of the `MultiBx` b is of type `BaseBx` which has some additional methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cNndZSKRIwTu",
   "metadata": {
    "id": "cNndZSKRIwTu"
   },
   "outputs": [],
   "source": [
    "[b_.area() for b_ in b] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2GbaFyiLe5i9",
   "metadata": {
    "id": "2GbaFyiLe5i9"
   },
   "source": [
    "Each `BaseBx` is also pseudo-iterable (calling an iterator returns `self` itself and not the coordinates or labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HVM98OhpeqtE",
   "metadata": {
    "id": "HVM98OhpeqtE"
   },
   "outputs": [],
   "source": [
    "b_ = b[0]\n",
    "[x for x in b_]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vvR71yvFLpJP",
   "metadata": {
    "id": "vvR71yvFLpJP"
   },
   "source": [
    "We can also stack the `BxTypes`. Issues a `UserWarning` if we try to add `BaseBx`+`MultiBx` or `BaseBx`+`BaseBx`. This is to preserve the philosophy of a `BaseBx`, since adding something to a `BaseBx`, which should technically only hold a single coordinate and label, makes the result a `MultiBx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4MoIsPvELiU9",
   "metadata": {
    "id": "4MoIsPvELiU9"
   },
   "outputs": [],
   "source": [
    "b_s = b_ + b_\n",
    "b_s.coords, b_s.label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "O7xYJ7dnqLHO",
   "metadata": {
    "id": "O7xYJ7dnqLHO"
   },
   "source": [
    "To safely add two boxes, use `basics.stack_bxs()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sQHq7cerqKwg",
   "metadata": {
    "id": "sQHq7cerqKwg"
   },
   "outputs": [],
   "source": [
    "stack_bxs(b_, b_).coords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2F8C1i4pfJdB",
   "metadata": {
    "id": "2F8C1i4pfJdB"
   },
   "source": [
    "From `v1.0.0` `BaseBx` can be iterated. What does it mean to iterate a single coordinate. Technically it should return each point of the coordinate. But `BaseBx` behaves differently on being iterated. It returns the `BaseBx` itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opYTZmF8q44u",
   "metadata": {
    "id": "opYTZmF8q44u"
   },
   "outputs": [],
   "source": [
    "[x for x in b_]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WWZAA6T6rEeb",
   "metadata": {
    "id": "WWZAA6T6rEeb"
   },
   "source": [
    "To truly iterate over the coordinates and label, one must do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "w-kSi4hbeuQ6",
   "metadata": {
    "id": "w-kSi4hbeuQ6"
   },
   "outputs": [],
   "source": [
    "[x for x in b_.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fYCnLDQrLqj",
   "metadata": {
    "id": "0fYCnLDQrLqj"
   },
   "outputs": [],
   "source": [
    "# or \n",
    "# [x.label for x in b_]\n",
    "[x.coords for x in b_]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WbpnuFiYMcEc",
   "metadata": {
    "id": "WbpnuFiYMcEc"
   },
   "source": [
    "Coming back to the `MultiBx` types, we can display the coordinates of the valid boxes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "H9xNlXqNI0zF",
   "metadata": {
    "id": "H9xNlXqNI0zF"
   },
   "outputs": [],
   "source": [
    "[b_.coords for b_ in b]  # selected boxes only!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6YLj06rglT18",
   "metadata": {
    "id": "6YLj06rglT18"
   },
   "source": [
    "Displaying the labels of valid boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5jcrwsljlQ-A",
   "metadata": {
    "id": "5jcrwsljlQ-A"
   },
   "outputs": [],
   "source": [
    "[b_.label for b_ in b]  # selected boxes only!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DzIGBgxdJsoP",
   "metadata": {
    "id": "DzIGBgxdJsoP"
   },
   "source": [
    "We can ofcourse see all the 16 boxes calculated by `anchor.bx()` from the `MultiBx` as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jS8o0sLTJsLL",
   "metadata": {
    "id": "jS8o0sLTJsLL"
   },
   "outputs": [],
   "source": [
    "b.coords, b.label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tHvfzubiJTnR",
   "metadata": {
    "id": "tHvfzubiJTnR"
   },
   "source": [
    "> The `vis.VisBx` internally converts all coordinates in `list`/`json`/`ndarray` to a `MultiBx` and shows only `valid` boxes. \n",
    "\n",
    "We can also overlay the features generated by the model on the original image. `logits=True` generates random logits (`np.random.randn`) of the same shape as feature sizes for illustration purposes. \n",
    "\n",
    "To aid the explainability of the model, actual model logits can also be passed into the same parameter `logits` as an array or detached tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kL4LFB__Dny_",
   "metadata": {
    "id": "kL4LFB__Dny_"
   },
   "outputs": [],
   "source": [
    "# ask VisBx to use random logits with logits=True\n",
    "vis.VisBx(image_sz=image_sz, logits=True, feature_sz=feature_sz).show(anchors, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c_48pnKGKhiW",
   "metadata": {
    "id": "c_48pnKGKhiW"
   },
   "outputs": [],
   "source": [
    "# ask VisBx to use passed logits with logits=logits\n",
    "logits = np.random.randn(3,3)  # assuming these are model logits\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7gDCZkatrxLK",
   "metadata": {
    "id": "7gDCZkatrxLK"
   },
   "outputs": [],
   "source": [
    "v = vis.VisBx(image_sz=image_sz, logits=logits).show(anchors, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "z9_v0f05LLSx",
   "metadata": {
    "id": "z9_v0f05LLSx"
   },
   "source": [
    "We can hightlight them with a different color if needed. Anchor boxes generated with `named=True` parameter automatically sets the label for each box in the format: `{anchor_sfx}_{feature_sz}_{asp_ratio}_{box_number}`. `anchor_sfx` is also an optional parameter that can be passed to `anchor.bx()`. Here we change the color of one anchor box and one ground truth box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8MvvkIsyD8w9",
   "metadata": {
    "id": "8MvvkIsyD8w9"
   },
   "outputs": [],
   "source": [
    "labels[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "l0rx9RcODzsz",
   "metadata": {
    "id": "l0rx9RcODzsz"
   },
   "outputs": [],
   "source": [
    "v = vis.VisBx(image_sz=image_sz)\n",
    "v.show(anchors, labels, color={'a_3x3_1.0_4':'red', 'clock':'orange'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fb31ae",
   "metadata": {},
   "source": [
    "The box `a_3x3_1.0_4` is not fully highlighted due to overlapping edges of other anchor boxes. A quick and dirty fix to isolate the said box:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f27199",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "v.show([a for i, a in enumerate(anchors) if labels[i]=='a_3x3_1.0_4'], \n",
    "       [l for l in labels if l=='a_3x3_1.0_4'],\n",
    "       color={'a_3x3_1.0_4':'red', 'clock':'orange'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b699aa",
   "metadata": {
    "id": "a6b699aa",
    "papermill": {
     "duration": 0.030927,
     "end_time": "2022-01-15T18:00:29.751836",
     "exception": false,
     "start_time": "2022-01-15T18:00:29.720909",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Working with mulitple feature sizes and aspect ratios\n",
    "Finally we calculate anchor boxes for multiple feature sizes and aspect ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e5abf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T18:00:29.819942Z",
     "iopub.status.busy": "2022-01-15T18:00:29.818489Z",
     "iopub.status.idle": "2022-01-15T18:00:31.452954Z",
     "shell.execute_reply": "2022-01-15T18:00:31.453477Z",
     "shell.execute_reply.started": "2022-01-15T17:51:05.334974Z"
    },
    "id": "89e5abf3",
    "papermill": {
     "duration": 1.670961,
     "end_time": "2022-01-15T18:00:31.453682",
     "exception": false,
     "start_time": "2022-01-15T18:00:29.782721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_szs = [(3, 3), (2, 2)]\n",
    "asp_ratios = [1/2., 2.]\n",
    "\n",
    "anchors, labels = anchor.bxs(image_sz, feature_szs, asp_ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e545a09c",
   "metadata": {
    "id": "e545a09c",
    "papermill": {
     "duration": 0.03994,
     "end_time": "2022-01-15T18:00:31.535833",
     "exception": false,
     "start_time": "2022-01-15T18:00:31.495893",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This is essentially a wrapper to do list comprehension over the passed feature sizes and aspect ratios (but additionally stacks them together into an ndarray).\n",
    "\n",
    "```\n",
    "[anchor.bx(image_sz, f, ar) for f in feature_szs for ar in asp_ratios]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MyLwmBJFEQcn",
   "metadata": {
    "id": "MyLwmBJFEQcn"
   },
   "outputs": [],
   "source": [
    "labels[4], labels[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XoGYx-1JEK42",
   "metadata": {
    "id": "XoGYx-1JEK42"
   },
   "outputs": [],
   "source": [
    "v = vis.VisBx(image_sz=image_sz)\n",
    "v.show(anchors, labels, color={'a_3x3_0.5_4':'red', 'a_2x2_0.5_0':'red'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc162f5",
   "metadata": {
    "id": "3fc162f5",
    "papermill": {
     "duration": 0.039163,
     "end_time": "2022-01-15T18:00:31.616485",
     "exception": false,
     "start_time": "2022-01-15T18:00:31.577322",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As simple as that! Do leave a star or raise issues and suggestions on the project page if you found this useful! \n",
    "\n",
    "Project page: [GitHub](https://github.com/thatgeeman/pybx) \n",
    "\n",
    "PyPi Package: [PyBx](https://pypi.org/project/pybx/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bf2f62",
   "metadata": {
    "id": "a6bf2f62",
    "papermill": {
     "duration": 0.039503,
     "end_time": "2022-01-15T18:00:31.698358",
     "exception": false,
     "start_time": "2022-01-15T18:00:31.658855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "pybx_walkthrough.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pybx",
   "language": "python",
   "name": "pybx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 34.691937,
   "end_time": "2022-01-15T18:00:32.454202",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-01-15T17:59:57.762265",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
